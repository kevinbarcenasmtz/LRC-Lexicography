{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc71525e",
   "metadata": {},
   "source": [
    "Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "2dfae0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import Counter, defaultdict\n",
    "from typing import Dict, List, Set, Any\n",
    "import re\n",
    "from pprint import pprint\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_colwidth', 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "f44a2d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: starling_complete_data.json\n",
      "\n",
      "Top-level keys: ['metadata', 'records']\n"
     ]
    }
   ],
   "source": [
    "JSON_FILE = 'starling_complete_data.json'\n",
    "\n",
    "print(f\"Loading: {JSON_FILE}\")\n",
    "\n",
    "with open(JSON_FILE, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(f\"\\nTop-level keys: {list(data.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "c32027dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "METADATA\n",
      "======================================================================\n",
      "start_url..................... https://starlingdb.org/cgi-bin/response.cgi?root=config&basename=\\data\\drav\\dravet\n",
      "total_pages_scraped........... 111\n",
      "total_records................. 2211\n",
      "unique_entries................ 11303\n",
      "\n",
      "Total records in JSON: 2211\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"METADATA\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "metadata = data.get('metadata', {})\n",
    "for key, value in metadata.items():\n",
    "    print(f\"{key:.<30} {value}\")\n",
    "\n",
    "records = data.get('records', [])\n",
    "print(f\"\\nTotal records in JSON: {len(records)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "c800224b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_all_keys(records: List[Dict]) -> Dict:\n",
    "    \"\"\"\n",
    "    Recursively find ALL unique keys in the dataset, including nested sub_entries\n",
    "    \"\"\"\n",
    "    all_keys = Counter()\n",
    "    metadata_keys = set()\n",
    "    language_keys = set()\n",
    "    \n",
    "    def extract_keys(obj, depth=0):\n",
    "        \"\"\"Recursively extract keys from nested structure\"\"\"\n",
    "        if isinstance(obj, dict):\n",
    "            for key, value in obj.items():\n",
    "                all_keys[key] += 1\n",
    "                \n",
    "                # Classify key type\n",
    "                if key.startswith('_'):\n",
    "                    metadata_keys.add(key)\n",
    "                elif key not in ['Meaning', 'Number in DED', 'Notes']:\n",
    "                    language_keys.add(key)\n",
    "                \n",
    "                # Recurse into nested structures\n",
    "                if isinstance(value, (dict, list)):\n",
    "                    extract_keys(value, depth + 1)\n",
    "        \n",
    "        elif isinstance(obj, list):\n",
    "            for item in obj:\n",
    "                extract_keys(item, depth + 1)\n",
    "    \n",
    "    # Process all records\n",
    "    for record in records:\n",
    "        extract_keys(record)\n",
    "    \n",
    "    return {\n",
    "        'all_keys': all_keys,\n",
    "        'metadata_keys': sorted(metadata_keys),\n",
    "        'language_keys': sorted(language_keys)\n",
    "    }\n",
    "\n",
    "# Run analysis\n",
    "key_analysis = analyze_all_keys(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdecfc3",
   "metadata": {},
   "source": [
    "## Exporting json to separate language files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1dda92",
   "metadata": {},
   "source": [
    "Identify Base Language Names and Their Variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "9c240f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LANGUAGE STRUCTURE ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "Total base languages identified: 67\n",
      "\n",
      "Language Name                                   | Count  |\n",
      "------------------------------------------------------------\n",
      "Proto South Dravidian                           |  3,563\n",
      "Proto Telugu                                    |  3,011\n",
      "Proto Dravidian                                 |  2,211\n",
      "Proto Gondi Kui                                 |  2,154\n",
      "Proto Kolami Gadba                              |  2,026\n",
      "Proto Nilgiri                                   |  1,792\n",
      "Proto Kui Kuwi                                  |  1,426\n",
      "Tamil                                           |  1,425\n",
      "Proto Gondi                                     |  1,414\n",
      "Kannada                                         |  1,407\n",
      "Telugu                                          |  1,339\n",
      "Konda                                           |  1,266\n",
      "Malayalam                                       |  1,207\n",
      "Tulu                                            |  1,174\n",
      "Proto North Dravidian                           |  1,104 [merged]\n",
      "Proto Pengo Manda                               |    822\n",
      "Kota                                            |    761\n",
      "Kodagu                                          |    660\n",
      "Toda                                            |    655\n",
      "Parji                                           |    618\n",
      "Kui                                             |    493\n",
      "Kurukh                                          |    441\n",
      "Kolami                                          |    417\n",
      "Malto                                           |    413\n",
      "Naikri                                          |    379\n",
      "Pengo                                           |    374\n",
      "Koya Gondi                                      |    371\n",
      "Brahui                                          |    371\n",
      "Kuwi (Schulze)                                  |    368\n",
      "Kuwi (Fitzgerald)                               |    367\n",
      "Kuwi (Israel)                                   |    356\n",
      "Muria Gondi                                     |    353\n",
      "Maria Gondi                                     |    345\n",
      "Betul Gondi                                     |    343\n",
      "Sunkarametta Kuwi                               |    309\n",
      "Adilabad Gondi                                  |    305\n",
      "Salur Gadba                                     |    274\n",
      "Manda                                           |    270\n",
      "Ollari Gadba                                    |    238\n",
      "Naiki                                           |    237\n",
      "Mandla Gondi (Phailbus)                         |    213\n",
      "Maria Gondi (Mitchell)                          |    213\n",
      "Mandla Gondi (Williamson)                       |    202\n",
      "Seoni Gondi                                     |    196\n",
      "Telugu (Krishnamurti)                           |    188\n",
      "Kondekor Gadba                                  |    174\n",
      "Gommu Gondi                                     |    160\n",
      "Kinwat Kolami                                   |    159\n",
      "Kolami (Setumadhava Rao)                        |    146\n",
      "Parja Kuwi                                      |    126\n",
      "Yeotmal Gondi                                   |    120\n",
      "Poya Gadba                                      |    101\n",
      "Maria Gondi (Lind)                              |    101\n",
      "Chindwara Gondi                                 |     90\n",
      "Khuttia Kui                                     |     86\n",
      "Konda (Burrow/Bhattacharya)                     |     67\n",
      "Maria Gondi (Smith)                             |     58\n",
      "Kuwi (Mahanti)                                  |     49\n",
      "Tekriya Kuwi                                    |     47\n",
      "Inscriptional Telugu                            |     45\n",
      "Durg Gondi                                      |     38\n",
      "Chanda Gondi                                    |     36\n",
      "Dongriya Kuwi                                   |     32\n",
      "Mandla Gondi                                    |     13\n",
      "Irula                                           |     12\n",
      "Merolu Telugu                                   |      6\n",
      "Kasaba                                          |      2\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict, List, DefaultDict, TypedDict\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "\n",
    "class LanguageInfo(TypedDict):\n",
    "    has_meaning: bool\n",
    "    has_derivates: bool\n",
    "    has_etymology: bool\n",
    "    count: int\n",
    "\n",
    "\n",
    "class DisplayLanguageInfo(LanguageInfo):\n",
    "    variants: List[str]\n",
    "\n",
    "\n",
    "# --- Step 1: Extract structure from all_keys ---\n",
    "\n",
    "def extract_language_structure(all_keys: Counter[str]) -> Dict[str, LanguageInfo]:\n",
    "    \"\"\"\n",
    "    Identify base languages and their associated fields (meaning, derivates, etymology)\n",
    "    \"\"\"\n",
    "    excluded_keys = {\n",
    "        '_page', '_record_num', '_sub_entries', '_url', '_depth', '_content_hash', '_error',\n",
    "        'Meaning', 'Notes', 'Number in DED', 'Number in CVOTGD',\n",
    "        'Miscellaneous', 'Notes on correspondences', 'Stems',\n",
    "        'Dialectal forms', 'Dialectal forms (1)', 'Dialectal forms (2)',\n",
    "        'Dialectal forms (3)', 'Dialectal forms (4)',\n",
    "        \"Additional forms\", \"Additional Forms\"\n",
    "    }\n",
    "\n",
    "    language_info: DefaultDict[str, LanguageInfo] = defaultdict(lambda: {\n",
    "        'has_meaning': False,\n",
    "        'has_derivates': False,\n",
    "        'has_etymology': False,\n",
    "        'count': 0\n",
    "    })\n",
    "\n",
    "    for key, count in all_keys.items():\n",
    "        if key in excluded_keys:\n",
    "            continue\n",
    "\n",
    "        if key.endswith(' etymology'):\n",
    "            continue\n",
    "\n",
    "        if key.endswith(' meaning'):\n",
    "            base_lang = key.removesuffix(' meaning')\n",
    "            language_info[base_lang]['has_meaning'] = True\n",
    "        elif key.endswith(' derivates'):\n",
    "            base_lang = key.removesuffix(' derivates')\n",
    "            language_info[base_lang]['has_derivates'] = True\n",
    "        else:\n",
    "            language_info[key]['count'] = count\n",
    "\n",
    "    return dict(language_info)\n",
    "\n",
    "\n",
    "# --- Step 2: Normalize for display (merge variants, fix naming inconsistencies) ---\n",
    "\n",
    "def normalize_for_display(language_structure: Dict[str, LanguageInfo]) -> Dict[str, DisplayLanguageInfo]:\n",
    "    \"\"\"Merge similar language names for display\"\"\"\n",
    "    normalized: DefaultDict[str, DisplayLanguageInfo] = defaultdict(lambda: {\n",
    "        'has_meaning': False,\n",
    "        'has_derivates': False,\n",
    "        'has_etymology': False,\n",
    "        'count': 0,\n",
    "        'variants': []\n",
    "    })\n",
    "\n",
    "    for lang, info in language_structure.items():\n",
    "        # Normalize formatting (replace dashes with spaces)\n",
    "        canonical = lang.replace('-', ' ').strip()\n",
    "\n",
    "        n = normalized[canonical]\n",
    "        n['count'] += info['count']\n",
    "        n['has_meaning'] = n['has_meaning'] or info['has_meaning']\n",
    "        n['has_derivates'] = n['has_derivates'] or info['has_derivates']\n",
    "        n['has_etymology'] = n['has_etymology'] or info['has_etymology']\n",
    "        n['variants'].append(lang)\n",
    "\n",
    "    return dict(normalized)\n",
    "\n",
    "\n",
    "# --- Step 3: Run analysis and print summary ---\n",
    "\n",
    "# Example usage:\n",
    "language_structure = extract_language_structure(key_analysis[\"all_keys\"])\n",
    "language_structure_display = normalize_for_display(language_structure)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"LANGUAGE STRUCTURE ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nTotal base languages identified: {len(language_structure_display)}\\n\")\n",
    "\n",
    "sorted_languages = sorted(\n",
    "    language_structure_display.items(),\n",
    "    key=lambda x: x[1][\"count\"],\n",
    "    reverse=True\n",
    ")\n",
    "\n",
    "print(\"Language Name                                   | Count  |\")\n",
    "print(\"-\" * 60)\n",
    "for lang, info in sorted_languages:\n",
    "    merged_indicator = \" [merged]\" if len(info[\"variants\"]) > 1 else \"\"\n",
    "    print(f\"{lang:<47} | {info['count']:>6,}{merged_indicator}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33de3432",
   "metadata": {},
   "source": [
    "Define Common Fields and Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "150334e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common fields to extract: ['Meaning', 'Notes', 'Number in DED', 'Number in CVOTGD', 'Miscellaneous', 'Notes on correspondences', 'Stems', 'Additional forms', 'Additional Forms']\n",
      "\n",
      "Dialectal fields to extract: ['Dialectal forms', 'Dialectal forms (1)', 'Dialectal forms (2)', 'Dialectal forms (3)', 'Dialectal forms (4)']\n",
      "\n",
      "Metadata fields to extract: ['_depth', '_error', '_page', '_record_num', '_url']\n"
     ]
    }
   ],
   "source": [
    "# Common fields that should be checked in every record\n",
    "COMMON_FIELDS = [\n",
    "    'Meaning',\n",
    "    'Notes',\n",
    "    'Number in DED',\n",
    "    'Number in CVOTGD',\n",
    "    'Miscellaneous',\n",
    "    'Notes on correspondences',\n",
    "    'Stems',\n",
    "    'Additional forms',\n",
    "    \"Additional Forms\",\n",
    "]\n",
    "\n",
    "# Dialectal forms can be numbered\n",
    "DIALECTAL_FIELDS = [\n",
    "    'Dialectal forms',\n",
    "    'Dialectal forms (1)',\n",
    "    'Dialectal forms (2)',\n",
    "    'Dialectal forms (3)',\n",
    "    'Dialectal forms (4)',\n",
    "]\n",
    "\n",
    "# Metadata fields\n",
    "METADATA_FIELDS = [\n",
    "    '_depth',\n",
    "    '_error',\n",
    "    '_page',\n",
    "    '_record_num',\n",
    "    '_url',\n",
    "]\n",
    "\n",
    "print(\"Common fields to extract:\", COMMON_FIELDS)\n",
    "print(\"\\nDialectal fields to extract:\", DIALECTAL_FIELDS)\n",
    "print(\"\\nMetadata fields to extract:\", METADATA_FIELDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd6952d",
   "metadata": {},
   "source": [
    "Function to Flatten Records for a Specific Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "d084e238",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_language_variants(language_name: str, language_structure_display: Dict = None) -> List[str]:\n",
    "    \"\"\"\n",
    "    Return list of variant names to check for a given language.\n",
    "    \"\"\"\n",
    "    # If we have the display structure, use the stored variants\n",
    "    if language_structure_display and language_name in language_structure_display:\n",
    "        return language_structure_display[language_name]['variants']\n",
    "    \n",
    "    # Fallback: check both space and dash versions\n",
    "    variants = [language_name]\n",
    "    if ' ' in language_name:\n",
    "        variants.append(language_name.replace(' ', '-'))\n",
    "    if '-' in language_name:\n",
    "        variants.append(language_name.replace('-', ' '))\n",
    "    \n",
    "    return variants\n",
    "    \n",
    "# Cell: Fixed Extract Function - Handle Non-String Values\n",
    "def extract_language_entries(records: List[Dict], language_name: str, language_structure_display: Dict = None) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Extract all entries for a language, checking variant names if needed.\n",
    "    ALL etymology fields go into the single 'Etymology' column.\n",
    "    \"\"\"\n",
    "    variant_names = get_language_variants(language_name, language_structure_display)\n",
    "    entries = []\n",
    "    \n",
    "    def process_record(record: Dict, parent_meaning: str = \"\"):\n",
    "        if record.get('_circular_reference'):\n",
    "            return\n",
    "        \n",
    "        # Check all variant names\n",
    "        word = \"\"\n",
    "        for variant in variant_names:\n",
    "            word = record.get(variant, \"\").strip() if isinstance(record.get(variant, \"\"), str) else \"\"\n",
    "            if word:\n",
    "                break\n",
    "        \n",
    "        if word:\n",
    "            entry = {'Word': word}\n",
    "            \n",
    "            # Try to get meaning from any variant\n",
    "            specific_meaning = \"\"\n",
    "            for variant in variant_names:\n",
    "                val = record.get(f\"{variant} meaning\", \"\")\n",
    "                specific_meaning = val.strip() if isinstance(val, str) else str(val)\n",
    "                if specific_meaning:\n",
    "                    break\n",
    "            \n",
    "            general_meaning = record.get(\"Meaning\", \"\")\n",
    "            general_meaning = general_meaning.strip() if isinstance(general_meaning, str) else str(general_meaning)\n",
    "            entry['Meaning'] = specific_meaning if specific_meaning else (general_meaning or parent_meaning)\n",
    "            \n",
    "            # Derivates\n",
    "            entry['Derivates'] = \"\"\n",
    "            for variant in variant_names:\n",
    "                val = record.get(f\"{variant} derivates\", \"\")\n",
    "                derivates = val.strip() if isinstance(val, str) else str(val) if val else \"\"\n",
    "                if derivates:\n",
    "                    entry['Derivates'] = derivates\n",
    "                    break\n",
    "            \n",
    "            # Etymology - check language-specific first, then ANY etymology field\n",
    "            etymology = \"\"\n",
    "            \n",
    "            # 1. Check language-specific etymology (e.g., \"Tamil etymology\")\n",
    "            for variant in variant_names:\n",
    "                val = record.get(f\"{variant} etymology\", \"\")\n",
    "                etymology = val.strip() if isinstance(val, str) else str(val) if val else \"\"\n",
    "                if etymology:\n",
    "                    break\n",
    "            \n",
    "            # 2. If not found, check for ANY field ending with ' etymology'\n",
    "            if not etymology:\n",
    "                for key, value in record.items():\n",
    "                    if key.endswith(' etymology') and value:\n",
    "                        etymology = str(value).strip() if isinstance(value, str) else str(value)\n",
    "                        if etymology:\n",
    "                            break\n",
    "            \n",
    "            entry['Etymology'] = etymology\n",
    "            \n",
    "            # Common fields - handle non-string values\n",
    "            for field in COMMON_FIELDS:\n",
    "                val = record.get(field, \"\")\n",
    "                if isinstance(val, str):\n",
    "                    entry[field] = val.strip()\n",
    "                elif val:\n",
    "                    entry[field] = str(val)\n",
    "                else:\n",
    "                    entry[field] = \"\"\n",
    "            \n",
    "            # Dialectal forms - handle non-string values\n",
    "            for field in DIALECTAL_FIELDS:\n",
    "                val = record.get(field, \"\")\n",
    "                if isinstance(val, str):\n",
    "                    entry[field] = val.strip()\n",
    "                elif val:\n",
    "                    entry[field] = str(val)\n",
    "                else:\n",
    "                    entry[field] = \"\"\n",
    "            \n",
    "            # Metadata - keep as-is (might be int)\n",
    "            for field in METADATA_FIELDS:\n",
    "                entry[field] = record.get(field, \"\")\n",
    "            \n",
    "            entries.append(entry)\n",
    "        \n",
    "        # Recurse\n",
    "        current_meaning = record.get(\"Meaning\", \"\")\n",
    "        current_meaning = current_meaning if isinstance(current_meaning, str) else str(current_meaning) if current_meaning else \"\"\n",
    "        if not current_meaning:\n",
    "            current_meaning = parent_meaning\n",
    "            \n",
    "        if '_sub_entries' in record:\n",
    "            for sub_entry in record['_sub_entries']:\n",
    "                if isinstance(sub_entry, dict):\n",
    "                    process_record(sub_entry, current_meaning)\n",
    "    \n",
    "    for record in records:\n",
    "        process_record(record)\n",
    "    \n",
    "    return entries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043e65b4",
   "metadata": {},
   "source": [
    "Get List of All Languages to Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "1ad4ba74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LANGUAGES TO EXPORT: 67\n",
      "======================================================================\n",
      "  1. Adilabad Gondi                                [---]    305 entries\n",
      "  2. Betul Gondi                                   [---]    343 entries\n",
      "  3. Brahui                                        [---]    371 entries\n",
      "  4. Chanda Gondi                                  [---]     36 entries\n",
      "  5. Chindwara Gondi                               [---]     90 entries\n",
      "  6. Dongriya Kuwi                                 [---]     32 entries\n",
      "  7. Durg Gondi                                    [---]     38 entries\n",
      "  8. Gommu Gondi                                   [---]    160 entries\n",
      "  9. Inscriptional Telugu                          [---]     45 entries\n",
      " 10. Irula                                         [MD-]     12 entries\n",
      " 11. Kannada                                       [MD-]  1,407 entries\n",
      " 12. Kasaba                                        [MD-]      2 entries\n",
      " 13. Khuttia Kui                                   [---]     86 entries\n",
      " 14. Kinwat Kolami                                 [---]    159 entries\n",
      " 15. Kodagu                                        [MD-]    660 entries\n",
      " 16. Kolami                                        [---]    417 entries\n",
      " 17. Kolami (Setumadhava Rao)                      [---]    146 entries\n",
      " 18. Konda                                         [---]  1,266 entries\n",
      " 19. Konda (Burrow/Bhattacharya)                   [---]     67 entries\n",
      " 20. Kondekor Gadba                                [---]    174 entries\n",
      " 21. Kota                                          [---]    761 entries\n",
      " 22. Koya Gondi                                    [---]    371 entries\n",
      " 23. Kui                                           [---]    493 entries\n",
      " 24. Kurukh                                        [---]    441 entries\n",
      " 25. Kuwi (Fitzgerald)                             [---]    367 entries\n",
      " 26. Kuwi (Israel)                                 [---]    356 entries\n",
      " 27. Kuwi (Mahanti)                                [---]     49 entries\n",
      " 28. Kuwi (Schulze)                                [---]    368 entries\n",
      " 29. Malayalam                                     [MD-]  1,207 entries\n",
      " 30. Malto                                         [---]    413 entries\n",
      " 31. Manda                                         [---]    270 entries\n",
      " 32. Mandla Gondi                                  [---]     13 entries\n",
      " 33. Mandla Gondi (Phailbus)                       [---]    213 entries\n",
      " 34. Mandla Gondi (Williamson)                     [---]    202 entries\n",
      " 35. Maria Gondi                                   [---]    345 entries\n",
      " 36. Maria Gondi (Lind)                            [---]    101 entries\n",
      " 37. Maria Gondi (Mitchell)                        [---]    213 entries\n",
      " 38. Maria Gondi (Smith)                           [---]     58 entries\n",
      " 39. Merolu Telugu                                 [---]      6 entries\n",
      " 40. Muria Gondi                                   [---]    353 entries\n",
      " 41. Naiki                                         [---]    237 entries\n",
      " 42. Naikri                                        [---]    379 entries\n",
      " 43. Ollari Gadba                                  [---]    238 entries\n",
      " 44. Parja Kuwi                                    [---]    126 entries\n",
      " 45. Parji                                         [---]    618 entries\n",
      " 46. Pengo                                         [---]    374 entries\n",
      " 47. Poya Gadba                                    [---]    101 entries\n",
      " 48. Proto Dravidian                               [---]  2,211 entries\n",
      " 49. Proto Gondi                                   [---]  1,414 entries\n",
      " 50. Proto Gondi Kui                               [---]  2,154 entries\n",
      " 51. Proto Kolami Gadba                            [---]  2,026 entries\n",
      " 52. Proto Kui Kuwi                                [---]  1,426 entries\n",
      " 53. Proto Nilgiri                                 [---]  1,792 entries\n",
      " 54. Proto North Dravidian                         [---]  1,104 entries [merged]\n",
      " 55. Proto Pengo Manda                             [---]    822 entries\n",
      " 56. Proto South Dravidian                         [---]  3,563 entries\n",
      " 57. Proto Telugu                                  [---]  3,011 entries\n",
      " 58. Salur Gadba                                   [---]    274 entries\n",
      " 59. Seoni Gondi                                   [---]    196 entries\n",
      " 60. Sunkarametta Kuwi                             [---]    309 entries\n",
      " 61. Tamil                                         [MD-]  1,425 entries\n",
      " 62. Tekriya Kuwi                                  [---]     47 entries\n",
      " 63. Telugu                                        [---]  1,339 entries\n",
      " 64. Telugu (Krishnamurti)                         [---]    188 entries\n",
      " 65. Toda                                          [---]    655 entries\n",
      " 66. Tulu                                          [MD-]  1,174 entries\n",
      " 67. Yeotmal Gondi                                 [---]    120 entries\n"
     ]
    }
   ],
   "source": [
    "# Get all base language names (those that have actual word entries, not just etymology references)\n",
    "languages_to_export = []\n",
    "\n",
    "for lang_name, info in language_structure_display.items():\n",
    "    # Only export if it has actual entries (count > 0)\n",
    "    if info['count'] > 0:\n",
    "        languages_to_export.append(lang_name)\n",
    "        \n",
    "\n",
    "languages_to_export.sort()\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(f\"LANGUAGES TO EXPORT: {len(languages_to_export)}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for i, lang in enumerate(languages_to_export, 1):\n",
    "    # Use the display structure for counts and flags\n",
    "    info = language_structure_display[lang]\n",
    "    count = info['count']\n",
    "    has_meaning = \"M\" if info['has_meaning'] else \"-\"\n",
    "    has_derivates = \"D\" if info['has_derivates'] else \"-\"\n",
    "    has_etymology = \"E\" if info['has_etymology'] else \"-\"\n",
    "   \n",
    "    merged_indicator = \" [merged]\" if len(info['variants']) > 1 else \"\"\n",
    "    print(f\"{i:>3}. {lang:<45} [{has_meaning}{has_derivates}{has_etymology}] {count:>6,} entries{merged_indicator}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b131f6a4",
   "metadata": {},
   "source": [
    "Export Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "6c401c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_language_to_csv(records: List[Dict],\n",
    "                          language_name: str,\n",
    "                          output_dir: Path,\n",
    "                          language_structure_display: Dict = None) -> Dict:\n",
    "    \"\"\"\n",
    "    Export using the fixed extract function.\n",
    "    \"\"\"\n",
    "    entries = extract_language_entries(records, language_name, language_structure_display)\n",
    "    \n",
    "    if not entries:\n",
    "        return {'language': language_name, 'filename': None, 'entries': 0, 'status': 'no_entries'}\n",
    "    \n",
    "    df = pd.DataFrame(entries)\n",
    "    \n",
    "    # Reorder columns\n",
    "    priority_cols = ['Word', 'Meaning', 'Derivates', 'Etymology']\n",
    "    other_cols = [col for col in df.columns if col not in priority_cols]\n",
    "    ordered_cols = priority_cols + sorted(other_cols)\n",
    "    df = df[ordered_cols]\n",
    "    \n",
    "    # Filename\n",
    "    safe_name = re.sub(r'[^a-zA-Z0-9_()-]', '_', language_name)\n",
    "    safe_name = re.sub(r'_+', '_', safe_name)\n",
    "    filename = f\"{safe_name}.csv\"\n",
    "    filepath = output_dir / filename\n",
    "    \n",
    "    df.to_csv(filepath, index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    return {\n",
    "        'language': language_name,\n",
    "        'filename': filename,\n",
    "        'entries': len(entries),\n",
    "        'unique_words': df['Word'].nunique(),\n",
    "        'with_meaning': (df['Meaning'] != '').sum(),\n",
    "        'status': 'success'\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5603be1b",
   "metadata": {},
   "source": [
    "Full Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "e58cecc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "FULL EXPORT - ALL LANGUAGES\n",
      "======================================================================\n",
      "Exporting 67 languages...\n",
      "\n",
      "[1/67] Exporting Adilabad Gondi... OK (305 entries)\n",
      "[2/67] Exporting Betul Gondi... OK (343 entries)\n",
      "[3/67] Exporting Brahui... OK (371 entries)\n",
      "[4/67] Exporting Chanda Gondi... OK (36 entries)\n",
      "[5/67] Exporting Chindwara Gondi... OK (90 entries)\n",
      "[6/67] Exporting Dongriya Kuwi... OK (32 entries)\n",
      "[7/67] Exporting Durg Gondi... OK (38 entries)\n",
      "[8/67] Exporting Gommu Gondi... OK (160 entries)\n",
      "[9/67] Exporting Inscriptional Telugu... OK (45 entries)\n",
      "[10/67] Exporting Irula... OK (12 entries)\n",
      "[11/67] Exporting Kannada... OK (1407 entries)\n",
      "[12/67] Exporting Kasaba... OK (2 entries)\n",
      "[13/67] Exporting Khuttia Kui... OK (86 entries)\n",
      "[14/67] Exporting Kinwat Kolami... OK (159 entries)\n",
      "[15/67] Exporting Kodagu... OK (660 entries)\n",
      "[16/67] Exporting Kolami... OK (417 entries)\n",
      "[17/67] Exporting Kolami (Setumadhava Rao)... OK (146 entries)\n",
      "[18/67] Exporting Konda... OK (1266 entries)\n",
      "[19/67] Exporting Konda (Burrow/Bhattacharya)... OK (67 entries)\n",
      "[20/67] Exporting Kondekor Gadba... OK (174 entries)\n",
      "[21/67] Exporting Kota... OK (761 entries)\n",
      "[22/67] Exporting Koya Gondi... OK (371 entries)\n",
      "[23/67] Exporting Kui... OK (493 entries)\n",
      "[24/67] Exporting Kurukh... OK (441 entries)\n",
      "[25/67] Exporting Kuwi (Fitzgerald)... OK (367 entries)\n",
      "[26/67] Exporting Kuwi (Israel)... OK (356 entries)\n",
      "[27/67] Exporting Kuwi (Mahanti)... OK (49 entries)\n",
      "[28/67] Exporting Kuwi (Schulze)... OK (368 entries)\n",
      "[29/67] Exporting Malayalam... OK (1207 entries)\n",
      "[30/67] Exporting Malto... OK (413 entries)\n",
      "[31/67] Exporting Manda... OK (270 entries)\n",
      "[32/67] Exporting Mandla Gondi... OK (13 entries)\n",
      "[33/67] Exporting Mandla Gondi (Phailbus)... OK (213 entries)\n",
      "[34/67] Exporting Mandla Gondi (Williamson)... OK (202 entries)\n",
      "[35/67] Exporting Maria Gondi... OK (345 entries)\n",
      "[36/67] Exporting Maria Gondi (Lind)... OK (101 entries)\n",
      "[37/67] Exporting Maria Gondi (Mitchell)... OK (213 entries)\n",
      "[38/67] Exporting Maria Gondi (Smith)... OK (58 entries)\n",
      "[39/67] Exporting Merolu Telugu... OK (6 entries)\n",
      "[40/67] Exporting Muria Gondi... OK (353 entries)\n",
      "[41/67] Exporting Naiki... OK (237 entries)\n",
      "[42/67] Exporting Naikri... OK (379 entries)\n",
      "[43/67] Exporting Ollari Gadba... OK (238 entries)\n",
      "[44/67] Exporting Parja Kuwi... OK (126 entries)\n",
      "[45/67] Exporting Parji... OK (618 entries)\n",
      "[46/67] Exporting Pengo... OK (374 entries)\n",
      "[47/67] Exporting Poya Gadba... OK (101 entries)\n",
      "[48/67] Exporting Proto Dravidian... OK (2211 entries)\n",
      "[49/67] Exporting Proto Gondi... OK (1414 entries)\n",
      "[50/67] Exporting Proto Gondi Kui... OK (2154 entries)\n",
      "[51/67] Exporting Proto Kolami Gadba... OK (2026 entries)\n",
      "[52/67] Exporting Proto Kui Kuwi... OK (1426 entries)\n",
      "[53/67] Exporting Proto Nilgiri... OK (1792 entries)\n",
      "[54/67] Exporting Proto North Dravidian... OK (1104 entries)\n",
      "[55/67] Exporting Proto Pengo Manda... OK (822 entries)\n",
      "[56/67] Exporting Proto South Dravidian... OK (3563 entries)\n",
      "[57/67] Exporting Proto Telugu... OK (3011 entries)\n",
      "[58/67] Exporting Salur Gadba... OK (274 entries)\n",
      "[59/67] Exporting Seoni Gondi... OK (196 entries)\n",
      "[60/67] Exporting Sunkarametta Kuwi... OK (309 entries)\n",
      "[61/67] Exporting Tamil... OK (1425 entries)\n",
      "[62/67] Exporting Tekriya Kuwi... OK (47 entries)\n",
      "[63/67] Exporting Telugu... OK (1339 entries)\n",
      "[64/67] Exporting Telugu (Krishnamurti)... OK (188 entries)\n",
      "[65/67] Exporting Toda... OK (655 entries)\n",
      "[66/67] Exporting Tulu... OK (1174 entries)\n",
      "[67/67] Exporting Yeotmal Gondi... OK (120 entries)\n",
      "\n",
      "======================================================================\n",
      "EXPORT COMPLETE\n",
      "======================================================================\n",
      "Total files created: 67\n",
      "Total entries exported: 39,739\n",
      "Summary saved to: dravidlex_csv_output\\_EXPORT_SUMMARY.csv\n",
      "Full export code ready (currently commented out)\n",
      "Uncomment the code above to run full export after verifying test results\n"
     ]
    }
   ],
   "source": [
    "# Uncomment to run full export\n",
    "\n",
    "output_dir = Path('dravidlex_csv_output')\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"FULL EXPORT - ALL LANGUAGES\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Exporting {len(languages_to_export)} languages...\\n\")\n",
    "\n",
    "export_results = []\n",
    "\n",
    "for i, lang in enumerate(languages_to_export, 1):\n",
    "    print(f\"[{i}/{len(languages_to_export)}] Exporting {lang}...\", end=' ')\n",
    "    \n",
    "    result = export_language_to_csv(records, lang, output_dir, language_structure_display)\n",
    "    export_results.append(result)\n",
    "    \n",
    "    if result['status'] == 'success':\n",
    "        print(f\"OK ({result['entries']} entries)\")\n",
    "    else:\n",
    "        print(f\"SKIP (no entries)\")\n",
    "\n",
    "# Create summary\n",
    "summary_df = pd.DataFrame(export_results)\n",
    "summary_df = summary_df.sort_values('entries', ascending=False)\n",
    "summary_path = output_dir / '_EXPORT_SUMMARY.csv'\n",
    "summary_df.to_csv(summary_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"EXPORT COMPLETE\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Total files created: {(summary_df['status'] == 'success').sum()}\")\n",
    "print(f\"Total entries exported: {summary_df['entries'].sum():,}\")\n",
    "print(f\"Summary saved to: {summary_path}\")\n",
    "\n",
    "print(\"Full export code ready (currently commented out)\")\n",
    "print(\"Uncomment the code above to run full export after verifying test results\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nahuaLEX_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
