{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df95143d",
   "metadata": {},
   "source": [
    "# Nahuatl Notebook for the WHP_EarlyNahuatl_Dataset\n",
    "\n",
    "This notebook processes Nahuatl dictionary data, analyzing HTML tags, repairing malformed tags, and extracting citations and cross-references. This is a merged version of Todd's version and I where there is a SQLite-based data management approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8105d6",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f542ca7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import hashlib\n",
    "import glob\n",
    "import csv\n",
    "import sqlite3\n",
    "from collections import defaultdict, Counter\n",
    "from typing import List, Dict, Tuple, Optional, Union\n",
    "from inscriptis import get_text\n",
    "from bs4 import BeautifulSoup\n",
    "from pathlib import Path\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60814645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WHP_EarlyNahuatl_Data</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    name\n",
       "0  WHP_EarlyNahuatl_Data"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create working directory\n",
    "os.makedirs('working_files', exist_ok=True)\n",
    "\n",
    "# load in the SQLite database holding the WHP Dataset\n",
    "conn = sqlite3.connect('../../data/sqLiteDb/Whp_Raw_Dataset.db')\n",
    "table_name = \"WHP_EarlyNahuatl_Data\"\n",
    "\n",
    "tables_query = \"SELECT name FROM sqlite_master WHERE type='table';\"\n",
    "tables = pd.read_sql(tables_query, conn)\n",
    "tables\n",
    "\n",
    "\n",
    "# If there's issues check the following\n",
    "# Possible solutions:\n",
    "# 1. Ensure the db file is in the correct directory\n",
    "# 2. Check the exact filename\n",
    "# 3. Verify the file extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cff32578",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_excel(data_dict: Dict[str, pd.DataFrame], filename: str, directory: str = 'working_files'):\n",
    "    \"\"\"Save multiple DataFrames as sheets in an Excel file\"\"\"\n",
    "    filepath = os.path.join(directory, filename)\n",
    "    with pd.ExcelWriter(filepath, engine='openpyxl') as writer:\n",
    "        for sheet_name, df in data_dict.items():\n",
    "            # Truncate sheet name if too long (Excel limit is 31 characters)\n",
    "            clean_sheet_name = sheet_name[:31] if len(sheet_name) > 31 else sheet_name\n",
    "            df.to_excel(writer, sheet_name=clean_sheet_name, index=False)\n",
    "    print(f\"Saved to: {filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a92de2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataframe(df: pd.DataFrame, filename: str, directory: str = 'working_files'):\n",
    "    \"\"\"Save a single DataFrame to CSV\"\"\"\n",
    "    filepath = os.path.join(directory, filename)\n",
    "    df.to_csv(filepath, index=False)\n",
    "    print(f\"Saved to: {filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2643a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_sqlite(df: pd.DataFrame, table_name: str, conn: sqlite3.Connection, if_exists: str = 'replace'):\n",
    "    \"\"\"Save DataFrame to SQLite table\"\"\"\n",
    "    df.to_sql(table_name, conn, if_exists=if_exists, index=False)\n",
    "    print(f\"Saved to SQLite table: {table_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86643dc",
   "metadata": {},
   "source": [
    "## Step 1: Import Data and Create Working Copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5cdecdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_csv(filename: str) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"Load data and create a working copy\"\"\"\n",
    "    print(f\"Loading data from: {filename}\")\n",
    "\n",
    "    # Read the original data\n",
    "    original_df = pd.read_csv(filename)\n",
    "\n",
    "    # Create working copy\n",
    "    working_df = original_df.copy()\n",
    "\n",
    "    print(f\"Data loaded successfully:\")\n",
    "    print(f\"- Shape: {original_df.shape}\")\n",
    "    print(f\"- Columns: {list(original_df.columns)}\")\n",
    "\n",
    "    return original_df, working_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6b20cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_sqlite(db_path: str, table_name: str = \"WHP_EarlyNahuatl_Data\") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"Load data from SQLite and create a working copy\"\"\"\n",
    "    print(f\"Loading data from: {db_path}\")\n",
    "    \n",
    "    conn = sqlite3.connect(db_path)\n",
    "    original_df = pd.read_sql(f\"SELECT * FROM {table_name}\", conn)\n",
    "    working_df = original_df.copy()\n",
    "    \n",
    "    print(f\"Data loaded successfully:\")\n",
    "    print(f\"- Shape: {original_df.shape}\")\n",
    "    print(f\"- Columns: {list(original_df.columns)}\")\n",
    "    \n",
    "    # Don't close connection yet - return it for later use\n",
    "    return original_df, working_df, conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8466f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ref</th>\n",
       "      <th>Headword</th>\n",
       "      <th>Orthographic Variants</th>\n",
       "      <th>Principal English Translation</th>\n",
       "      <th>Attestations from sources in English</th>\n",
       "      <th>Attestations from sources in Spanish</th>\n",
       "      <th>Alonso de Molina</th>\n",
       "      <th>Frances Karttunen</th>\n",
       "      <th>Horacio Carochi / English</th>\n",
       "      <th>Andrés de Olmos</th>\n",
       "      <th>Lockhart’s Nahuatl as Written</th>\n",
       "      <th>themes</th>\n",
       "      <th>Spanish Loanword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WHP-171879</td>\n",
       "      <td>acazomo.</td>\n",
       "      <td>accaçomo, acaçomo</td>\n",
       "      <td>&lt;p&gt;perhaps not (adverb) (see Molina)&lt;/p&gt;</td>\n",
       "      <td>&lt;p&gt;acaçomo iuhqui yez yn anoço yuhquiez = whet...</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;p&gt;Acaçomo. quiça no. Aduerbio.&lt;br /&gt; &lt;bibl&gt; A...</td>\n",
       "      <td>&lt;p&gt;AHCAZOMŌ perhaps not / quizá no (M).  In on...</td>\n",
       "      <td>&lt;p&gt;àcaçomō = perhaps not&lt;br /&gt; &lt;bibl&gt;Horacio C...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WHP-171881</td>\n",
       "      <td>ayac.</td>\n",
       "      <td>aiaac</td>\n",
       "      <td>&lt;p&gt;no one; nobody; or, for someone to be absen...</td>\n",
       "      <td>&lt;p&gt;aiaac mic in mexica = None of the Mexica di...</td>\n",
       "      <td>&lt;p&gt;ayac guincuiliz = no se la quite nadie (Tla...</td>\n",
       "      <td>&lt;p&gt;Ayac. ninguno, o nadie o estar alguno ausen...</td>\n",
       "      <td>&lt;p&gt;AYĀC no one / ninguno, o nadie (M) See AH-,...</td>\n",
       "      <td>&lt;p&gt;ayāc = no one&lt;br /&gt; &lt;bibl&gt;Horacio Carochi, ...</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;p&gt;no one; nobody; or, for someone to be absen...</td>\n",
       "      <td>None</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WHP-171882</td>\n",
       "      <td>acan.</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;p&gt;nowhere, no place (see Molina, Karttunen, L...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;p&gt;acan. en ninguna parte o lugar. aduerbio.&lt;b...</td>\n",
       "      <td>&lt;p&gt;AHCĀN nowhere / en ninguna parte o lugar (M...</td>\n",
       "      <td>&lt;p&gt;àcān = nowhere&lt;br /&gt; &lt;bibl&gt;Horacio Carochi,...</td>\n",
       "      <td>&lt;p&gt;en ningun lugar, por, de, etc.&lt;br /&gt; &lt;bibl&gt;...</td>\n",
       "      <td>&lt;p&gt;ahcān = (particle) nowhere&lt;br /&gt; &lt;bibl&gt;Jame...</td>\n",
       "      <td>Cardinal Directions, Cosmos</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Ref  Headword Orthographic Variants  \\\n",
       "0  WHP-171879  acazomo.     accaçomo, acaçomo   \n",
       "1  WHP-171881     ayac.                 aiaac   \n",
       "2  WHP-171882     acan.                  None   \n",
       "\n",
       "                       Principal English Translation  \\\n",
       "0          <p>perhaps not (adverb) (see Molina)</p>    \n",
       "1  <p>no one; nobody; or, for someone to be absen...   \n",
       "2  <p>nowhere, no place (see Molina, Karttunen, L...   \n",
       "\n",
       "                Attestations from sources in English  \\\n",
       "0  <p>acaçomo iuhqui yez yn anoço yuhquiez = whet...   \n",
       "1  <p>aiaac mic in mexica = None of the Mexica di...   \n",
       "2                                               None   \n",
       "\n",
       "                Attestations from sources in Spanish  \\\n",
       "0                                               None   \n",
       "1  <p>ayac guincuiliz = no se la quite nadie (Tla...   \n",
       "2                                               None   \n",
       "\n",
       "                                    Alonso de Molina  \\\n",
       "0  <p>Acaçomo. quiça no. Aduerbio.<br /> <bibl> A...   \n",
       "1  <p>Ayac. ninguno, o nadie o estar alguno ausen...   \n",
       "2  <p>acan. en ninguna parte o lugar. aduerbio.<b...   \n",
       "\n",
       "                                   Frances Karttunen  \\\n",
       "0  <p>AHCAZOMŌ perhaps not / quizá no (M).  In on...   \n",
       "1  <p>AYĀC no one / ninguno, o nadie (M) See AH-,...   \n",
       "2  <p>AHCĀN nowhere / en ninguna parte o lugar (M...   \n",
       "\n",
       "                           Horacio Carochi / English  \\\n",
       "0  <p>àcaçomō = perhaps not<br /> <bibl>Horacio C...   \n",
       "1  <p>ayāc = no one<br /> <bibl>Horacio Carochi, ...   \n",
       "2  <p>àcān = nowhere<br /> <bibl>Horacio Carochi,...   \n",
       "\n",
       "                                     Andrés de Olmos  \\\n",
       "0                                               None   \n",
       "1                                               None   \n",
       "2  <p>en ningun lugar, por, de, etc.<br /> <bibl>...   \n",
       "\n",
       "                       Lockhart’s Nahuatl as Written  \\\n",
       "0                                               None   \n",
       "1  <p>no one; nobody; or, for someone to be absen...   \n",
       "2  <p>ahcān = (particle) nowhere<br /> <bibl>Jame...   \n",
       "\n",
       "                        themes Spanish Loanword  \n",
       "0                         None               No  \n",
       "1                         None               No  \n",
       "2  Cardinal Directions, Cosmos               No  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ref', 'Headword', 'Orthographic Variants', 'Principal English Translation', 'Attestations from sources in English', 'Attestations from sources in Spanish', 'Alonso de Molina', 'Frances Karttunen', 'Horacio Carochi / English', 'Andrés de Olmos', 'Lockhart’s Nahuatl as Written', 'themes', 'Spanish Loanword']\n"
     ]
    }
   ],
   "source": [
    "# Load your data\n",
    "\n",
    "original_df = pd.read_sql(\"SELECT * FROM WHP_EarlyNahuatl_Data\", conn)\n",
    "df = original_df.copy(deep=True)\n",
    "\n",
    "query = \"SELECT * FROM WHP_EarlyNahuatl_Data LIMIT 3;\"\n",
    "whp_dataset = pd.read_sql(query, conn)\n",
    "display(whp_dataset)\n",
    "\n",
    "cursor = conn.execute(f\"PRAGMA table_info({table_name})\")\n",
    "columns_info = cursor.fetchall()\n",
    "column_names = [col[1] for col in columns_info]\n",
    "\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f1d64e",
   "metadata": {},
   "source": [
    "## Step 2: Save Intermediate Stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f613b686",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_intermediate_stage(df: pd.DataFrame, stage_name: str):\n",
    "    \"\"\"Save intermediate processing stage\"\"\"\n",
    "    filename = f\"{stage_name}_stage.csv\"\n",
    "    save_dataframe(df, filename)\n",
    "    return df\n",
    "\n",
    "def save_intermediate_stage_sqlite(df: pd.DataFrame, stage_name: str, conn: sqlite3.Connection):\n",
    "    \"\"\"Save intermediate processing stage to SQLite\"\"\"\n",
    "    table_name = f\"{stage_name}_stage\"\n",
    "    save_to_sqlite(df, table_name, conn)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45105fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save initial stage\n",
    "# save_intermediate_stage_sqlite(df, \"01_initial\", conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ca7114",
   "metadata": {},
   "source": [
    "## Step 3: HTML Tag Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c717f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HTMLTagAnalyzer:\n",
    "    def __init__(self):\n",
    "        # HTML tags\n",
    "        self.html_tags = {\n",
    "            'p', 'br', 'div', 'span', 'a', 'b', 'i', 'u', 'strong', 'em',\n",
    "            'h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'ul', 'ol', 'li', 'table',\n",
    "            'tr', 'td', 'th', 'img', 'link', 'meta', 'head', 'body', 'html',\n",
    "            'bibl', 'title', 'sup', 'sub', 'del'\n",
    "        }\n",
    "        \n",
    "        # Define columns that should contain HTML content\n",
    "        self.content_columns = [\n",
    "            'Principal English Translation',\n",
    "            'Attestations from sources in English',\n",
    "            'Attestations from sources in Spanish',\n",
    "            'Alonso de Molina',\n",
    "            'Frances Karttunen', \n",
    "            'Horacio Carochi / English',\n",
    "            'Andrés de Olmos',\n",
    "            \"Lockhart's Nahuatl as Written\",\n",
    "            'Full Original Entry'\n",
    "        ]\n",
    "        \n",
    "        # Known malformed patterns to fix\n",
    "        self.malformed_patterns = {\n",
    "            r'</p</bibl>': '</p></bibl>',\n",
    "            r'<bibl<': '<bibl>',\n",
    "            r'</bibbl>': '</bibl>',\n",
    "            r'<bibbl>': '<bibl>',\n",
    "            r'<bobl>': '<bibl>',\n",
    "            r'</bobl>': '</bibl>',\n",
    "            r'<b9bl>': '<bibl>',\n",
    "            r'<bibi>': '<bibl>',\n",
    "            r'<bibl></p>': '</bibl></p>',\n",
    "        }\n",
    "    \n",
    "    def detect_malformed_tags(self, text: str) -> List[tuple]:\n",
    "        \"\"\"Detect specific malformed tag patterns\"\"\"\n",
    "        if pd.isna(text) or text == '':\n",
    "            return []\n",
    "        \n",
    "        malformed_found = []\n",
    "        text_str = str(text)\n",
    "        \n",
    "        # Check for known malformed patterns\n",
    "        for pattern, replacement in self.malformed_patterns.items():\n",
    "            if re.search(pattern, text_str):\n",
    "                malformed_found.append((pattern, replacement))\n",
    "        \n",
    "        # Define self-closing tags that shouldn't be counted in pair matching\n",
    "        self_closing_tags = {'br', 'hr', 'img', 'input', 'meta', 'link'}\n",
    "        \n",
    "        # Better tag counting using regex\n",
    "        for tag_name in self.html_tags:\n",
    "            if tag_name in self_closing_tags:\n",
    "                continue  # Skip self-closing tags\n",
    "            \n",
    "            # Use regex to properly count opening tags (with or without attributes)\n",
    "            # Matches <tag> or <tag attr=\"...\">~\n",
    "            open_pattern = f\"<{tag_name}(?:\\\\s+[^>]*)?>\"\n",
    "            close_pattern = f'</{tag_name}>'\n",
    "            \n",
    "            open_count = len(re.findall(open_pattern, text_str, re.IGNORECASE))\n",
    "            close_count = len(re.findall(close_pattern, text_str, re.IGNORECASE))\n",
    "            \n",
    "            if open_count != close_count:\n",
    "                malformed_found.append((f'<{tag_name}>', f'Mismatch: {open_count} open, {close_count} closed'))\n",
    "        return malformed_found\n",
    "    \n",
    "    def find_html_tags(self, text: str) -> List[str]:\n",
    "        \"\"\"Find all HTML-like tags in text with better handling of malformed tags\"\"\"\n",
    "        if pd.isna(text) or text == '':\n",
    "            return []\n",
    "        \n",
    "        # First fix known malformed patterns\n",
    "        text_str = str(text)\n",
    "        for pattern, replacement in self.malformed_patterns.items():\n",
    "            text_str = re.sub(pattern, replacement, text_str)\n",
    "        \n",
    "        # Then find tags\n",
    "        pattern = r'</?[^<>]+/?>'\n",
    "        matches = re.findall(pattern, text_str)\n",
    "        return matches\n",
    "    \n",
    "    def analyze_html_tags_in_dataframe(self, df: pd.DataFrame, \n",
    "                                      columns_to_check: List[str] = None) -> Dict[str, pd.DataFrame]:\n",
    "        \"\"\"Analyze HTML tags only in relevant columns\"\"\"\n",
    "        results = {\n",
    "            'tag_by_row': [],\n",
    "            'tag_summary': [],\n",
    "            'malformed_tags': []\n",
    "        }\n",
    "        \n",
    "        # Use specified columns or default to content columns\n",
    "        if columns_to_check is None:\n",
    "            columns_to_check = [col for col in self.content_columns if col in df.columns]\n",
    "        \n",
    "        # Track tags by row - only in relevant columns\n",
    "        for idx, row in df.iterrows():\n",
    "            for col in columns_to_check:\n",
    "                if col not in df.columns:\n",
    "                    continue\n",
    "                    \n",
    "                cell_value = row[col]\n",
    "                if pd.notna(cell_value) and cell_value != '':\n",
    "                    # Check for malformed tags first\n",
    "                    malformed = self.detect_malformed_tags(cell_value)\n",
    "                    if malformed:\n",
    "                        for pattern, fix in malformed:\n",
    "                            results['malformed_tags'].append({\n",
    "                                'Row': idx,\n",
    "                                'Column': col,\n",
    "                                'Pattern': pattern,\n",
    "                                'Suggested_Fix': fix,\n",
    "                                'Context': str(cell_value)[:100] + '...' if len(str(cell_value)) > 100 else str(cell_value)\n",
    "                            })\n",
    "                    \n",
    "                    # Find tags\n",
    "                    tags = self.find_html_tags(cell_value)\n",
    "                    for tag in tags:\n",
    "                        is_valid = self.is_valid_html_tag(tag)\n",
    "                        context = self.get_tag_context(cell_value, tag)\n",
    "                        results['tag_by_row'].append({\n",
    "                            'Row': idx,\n",
    "                            'Column': col,\n",
    "                            'Tag': tag,\n",
    "                            'Is_Valid_HTML': is_valid,\n",
    "                            'Context': context\n",
    "                        })\n",
    "        \n",
    "        # Create summaries\n",
    "        if results['tag_by_row']:\n",
    "            tag_by_row_df = pd.DataFrame(results['tag_by_row'])\n",
    "            \n",
    "            # Tag summary\n",
    "            tag_counts = Counter([item['Tag'] for item in results['tag_by_row']])\n",
    "            tag_locations = defaultdict(list)\n",
    "            \n",
    "            for item in results['tag_by_row']:\n",
    "                tag_locations[item['Tag']].append(f\"Row {item['Row']}, Col {item['Column']}\")\n",
    "            \n",
    "            for tag, count in tag_counts.items():\n",
    "                first_occurrence = next(item for item in results['tag_by_row'] if item['Tag'] == tag)\n",
    "                results['tag_summary'].append({\n",
    "                    'Tag': tag,\n",
    "                    'Count': count,\n",
    "                    'Is_Valid_HTML': first_occurrence['Is_Valid_HTML'],\n",
    "                    'Locations': '; '.join(tag_locations[tag][:5]) + ('...' if len(tag_locations[tag]) > 5 else ''),\n",
    "                    'Sample_Context': first_occurrence['Context']\n",
    "                })\n",
    "            \n",
    "            tag_summary_df = pd.DataFrame(results['tag_summary']).sort_values('Count', ascending=False)\n",
    "        else:\n",
    "            tag_by_row_df = pd.DataFrame()\n",
    "            tag_summary_df = pd.DataFrame()\n",
    "        \n",
    "        malformed_df = pd.DataFrame(results['malformed_tags']) if results['malformed_tags'] else pd.DataFrame()\n",
    "        \n",
    "        return {\n",
    "            'HTML_Tags_by_Row': tag_by_row_df,\n",
    "            'HTML_Tags_Summary': tag_summary_df,\n",
    "            'Malformed_Tags': malformed_df\n",
    "        }\n",
    "    \n",
    "    def is_valid_html_tag(self, tag: str) -> bool:\n",
    "        \"\"\"Check if a tag is a valid HTML tag with better error handling\"\"\"\n",
    "        try:\n",
    "            # Handle malformed tags better\n",
    "            if '<//' in tag or '><' in tag:  # Clearly malformed\n",
    "                return False\n",
    "            \n",
    "            # Remove < > and any attributes, get just the tag name\n",
    "            clean_tag = re.sub(r'^</?([^>\\s/]+).*>$', r'\\1', tag).lower()\n",
    "            \n",
    "            # Additional check for malformed tags\n",
    "            if '/' in clean_tag or '<' in clean_tag or '>' in clean_tag:\n",
    "                return False\n",
    "                \n",
    "            return clean_tag in self.html_tags\n",
    "        except:\n",
    "            return False\n",
    "    \n",
    "    def get_tag_context(self, text: str, tag: str, context_chars: int = 50) -> str:\n",
    "        \"\"\"Get context around a tag occurrence\"\"\"\n",
    "        if pd.isna(text) or text == '':\n",
    "            return ''\n",
    "        \n",
    "        text_str = str(text)\n",
    "        tag_pos = text_str.find(tag)\n",
    "        if tag_pos == -1:\n",
    "            return ''\n",
    "        \n",
    "        start = max(0, tag_pos - context_chars)\n",
    "        end = min(len(text_str), tag_pos + len(tag) + context_chars)\n",
    "        context = text_str[start:end]\n",
    "        \n",
    "        # Mark the tag in the context\n",
    "        tag_in_context = context.replace(tag, f\"[[[{tag}]]]\")\n",
    "        return tag_in_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3026a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: working_files\\02_html_tag_analysis.xlsx\n"
     ]
    }
   ],
   "source": [
    "html_analyzer = HTMLTagAnalyzer()\n",
    "html_results = html_analyzer.analyze_html_tags_in_dataframe(df)\n",
    "\n",
    "html_results['HTML_Tags_Summary'].to_sql('html_tag_analysis', conn, if_exists='replace', index=False)\n",
    "html_results['Malformed_Tags'].to_sql('malformed_tags', conn, if_exists='replace', index=False)\n",
    "\n",
    "# save_intermediate_stage_sqlite(df, \"02_htmltag_analysis\", conn)\n",
    "save_to_excel(html_results, \"02_html_tag_analysis.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd09fe05",
   "metadata": {},
   "source": [
    "## Step 4: Malformed Tag Detection and Repair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "83b1a2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MalformedTagRepairer:\n",
    "    def __init__(self):\n",
    "        self.html_analyzer = HTMLTagAnalyzer()\n",
    "        \n",
    "        # Specific patterns for actual HTML malformations\n",
    "        self.html_malformation_patterns = {\n",
    "            # Bibliography tag typos\n",
    "            r'</bibbl>': '</bibl>',\n",
    "            r'<bibbl>': '<bibl>',\n",
    "            r'<\\?bibl>': '<bibl>',\n",
    "            r'<bibl<': '<bibl>',\n",
    "            r'</bobl>': '</bibl>',\n",
    "            r'<bobl>': '<bibl>',\n",
    "            r'<b9bl>': '<bibl>',\n",
    "            r'<bibi>': '<bibl>',\n",
    "            \n",
    "            # Paragraph tag issues\n",
    "            r'</p</bibl>': '</p></bibl>',\n",
    "            r'<p<': '<p>',\n",
    "            r'</p>p>': '</p>',\n",
    "            \n",
    "            # Structural issues\n",
    "            r'<<(\\w+)>': r'<\\1>',        # Double opening: <<bibl> → <bibl>\n",
    "            r'<(\\w+)>>': r'<\\1>',        # Double closing: <bibl>> → <bibl>\n",
    "            r'<(\\w+)\\s+<': r'<\\1>',      # Unclosed with new tag: <bibl <p> → <bibl>\n",
    "            \n",
    "            # Common typos\n",
    "            r'<stron>': '<strong>',\n",
    "            r'</stron>': '</strong>',\n",
    "            r'<em >': '<em>',\n",
    "            r'< (\\w+)>': r'<\\1>',        # Space after bracket: < bibl> → <bibl>\n",
    "        }\n",
    "        \n",
    "        # HTML tag patterns that indicate this IS supposed to be HTML\n",
    "        self.html_indicators = [\n",
    "            r'^</?(?:bibl|p|strong|em|b|i|u|sup|sub|div|span|a|br|h[1-6])[\\s>]',\n",
    "            r'</\\w+>$',                  # Closing tags\n",
    "            r'<\\w+\\s+\\w+=\"[^\"]*\"',      # Tags with attributes\n",
    "        ]\n",
    "\n",
    "    def is_definitely_non_html(self, tag: str) -> bool:\n",
    "        \"\"\"Conservative check - is this definitely NOT HTML?\"\"\"\n",
    "        for pattern in self.non_html_patterns:\n",
    "            if re.search(pattern, tag):\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def is_close_to_html(self, tag: str) -> bool:\n",
    "        \"\"\"MUCH more conservative - only obvious HTML-like malformations\"\"\"\n",
    "        # If it's definitely non-HTML content, don't even consider it\n",
    "        if self.is_definitely_non_html(tag):\n",
    "            return False\n",
    "        \n",
    "        # Only consider malformed if it's in our exact repair list\n",
    "        if tag in self.exact_repairs:\n",
    "            return True\n",
    "            \n",
    "        # Or if it has obvious HTML tag structure problems\n",
    "        malformed_patterns = [\n",
    "            r'<[^>]*</[^>]*>',  # Mixed opening/closing in one tag\n",
    "            r'</[^>]*<[^>]*>',  # Reversed brackets  \n",
    "            r'<[^>]*<[^>]*>',   # Double opening brackets\n",
    "        ]\n",
    "        \n",
    "        for pattern in malformed_patterns:\n",
    "            if re.search(pattern, tag):\n",
    "                return True\n",
    "                \n",
    "        return False\n",
    "    \n",
    "    def is_likely_malformed_html(self, tag: str) -> bool:\n",
    "        \"\"\"Check if this tag looks like malformed HTML (not just non-HTML content)\"\"\"\n",
    "        tag_lower = tag.lower()\n",
    "        \n",
    "        # Check if it matches any HTML indicators\n",
    "        for pattern in self.html_indicators:\n",
    "            if re.search(pattern, tag_lower):\n",
    "                return True\n",
    "        \n",
    "        # Check against known malformation patterns\n",
    "        for pattern in self.html_malformation_patterns.keys():\n",
    "            if re.search(pattern, tag):\n",
    "                return True\n",
    "                \n",
    "        return False\n",
    "    \n",
    "    \n",
    "\n",
    "    def find_malformed_tags(self, text: str) -> List[str]:\n",
    "        \"\"\"Find only actual malformed HTML tags\"\"\"\n",
    "        if pd.isna(text) or text == '':\n",
    "            return []\n",
    "\n",
    "        malformed_tags = []\n",
    "        \n",
    "        # Direct pattern matching for known malformations\n",
    "        for pattern, replacement in self.html_malformation_patterns.items():\n",
    "            matches = re.findall(pattern, str(text))\n",
    "            malformed_tags.extend(matches)\n",
    "        \n",
    "        # Additional check for malformed structure\n",
    "        all_brackets = re.findall(r'<[^<>]*>', str(text))\n",
    "        for tag in all_brackets:\n",
    "            if (not self.html_analyzer.is_valid_html_tag(tag) and \n",
    "                self.is_likely_malformed_html(tag) and\n",
    "                tag not in malformed_tags):  # Avoid duplicates\n",
    "                malformed_tags.append(tag)\n",
    "        \n",
    "        return malformed_tags\n",
    "\n",
    "    def is_close_to_html(self, tag: str) -> bool:\n",
    "        \"\"\"Check if a malformed tag is close to valid HTML\"\"\"\n",
    "        malformed_patterns = [\n",
    "            r'<[^>]*</[^>]*>',  # Mixed opening/closing\n",
    "            r'</[^>]*<[^>]*>',  # Reversed brackets\n",
    "            r'<[^>]*<[^>]*>',   # Double opening\n",
    "            r'<[^/>][^>]*[^/]>$', # Missing closing slash or improper format\n",
    "        ]\n",
    "\n",
    "        for pattern in malformed_patterns:\n",
    "            if re.search(pattern, tag):\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def suggest_repair(self, tag: str) -> str:\n",
    "        \"\"\"Suggest repair for malformed HTML tags\"\"\"\n",
    "        tag = tag.strip()\n",
    "        \n",
    "        # Check direct pattern matches first\n",
    "        for pattern, replacement in self.html_malformation_patterns.items():\n",
    "            if re.search(pattern, tag):\n",
    "                return re.sub(pattern, replacement, tag)\n",
    "        \n",
    "        # Additional repair logic\n",
    "        tag_lower = tag.lower()\n",
    "        \n",
    "        # Fix common spacing issues\n",
    "        if re.match(r'^<\\s+\\w+', tag):\n",
    "            return re.sub(r'^<\\s+', '<', tag)\n",
    "        if re.match(r'^<\\w+\\s+>', tag):\n",
    "            return re.sub(r'\\s+>$', '>', tag)\n",
    "            \n",
    "        # Return unchanged if no clear repair\n",
    "        return tag\n",
    "    def analyze_malformed_tags(self, df: pd.DataFrame) -> Dict[str, pd.DataFrame]:\n",
    "        \"\"\"Analyze only actual malformed HTML tags across DataFrame\"\"\"\n",
    "        results = {\n",
    "            'malformed_by_row': [],\n",
    "            'malformed_summary': []\n",
    "        }\n",
    "\n",
    "        print(\"Scanning for actual HTML malformations...\")\n",
    "        \n",
    "        for idx, row in df.iterrows():\n",
    "            for col in df.columns:\n",
    "                cell_value = row[col]\n",
    "                if pd.notna(cell_value) and cell_value != '':\n",
    "                    malformed_tags = self.find_malformed_tags(cell_value)\n",
    "                    for tag in malformed_tags:\n",
    "                        context = self.html_analyzer.get_tag_context(cell_value, tag)\n",
    "                        suggested_repair = self.suggest_repair(tag)\n",
    "                        results['malformed_by_row'].append({\n",
    "                            'Row': idx,\n",
    "                            'Column': col,\n",
    "                            'Malformed_Tag': tag,\n",
    "                            'Suggested_Repair': suggested_repair,\n",
    "                            'Context': context\n",
    "                        })\n",
    "\n",
    "        # Create summary\n",
    "        tag_counts = Counter([item['Malformed_Tag'] for item in results['malformed_by_row']])\n",
    "        tag_locations = defaultdict(list)\n",
    "\n",
    "        for item in results['malformed_by_row']:\n",
    "            tag_locations[item['Malformed_Tag']].append(f\"Row {item['Row']}, Col {item['Column']}\")\n",
    "\n",
    "        for tag, count in tag_counts.items():\n",
    "            first_occurrence = next(item for item in results['malformed_by_row'] if item['Malformed_Tag'] == tag)\n",
    "            results['malformed_summary'].append({\n",
    "                'Malformed_Tag': tag,\n",
    "                'Count': count,\n",
    "                'Suggested_Repair': first_occurrence['Suggested_Repair'],\n",
    "                'Locations': '; '.join(tag_locations[tag][:5]) + ('...' if len(tag_locations[tag]) > 5 else ''),\n",
    "                'Sample_Context': first_occurrence['Context']\n",
    "            })\n",
    "\n",
    "        malformed_by_row_df = pd.DataFrame(results['malformed_by_row'])\n",
    "        malformed_summary_df = pd.DataFrame(results['malformed_summary']).sort_values('Count', ascending=False)\n",
    "\n",
    "        print(f\"Found {len(malformed_by_row_df)} actual HTML malformations\")\n",
    "        \n",
    "        return {\n",
    "            'Malformed_Tags_by_Row': malformed_by_row_df,\n",
    "            'Malformed_Tags_Summary': malformed_summary_df\n",
    "        }\n",
    "\n",
    "    def repair_tags(self, df: pd.DataFrame, tag_to_repair: str, replacement: str,\n",
    "               scope: str = 'global', specific_column: str = None,\n",
    "               specific_row: int = None) -> pd.DataFrame:\n",
    "        \"\"\"Repair malformed tags in DataFrame\"\"\"\n",
    "        df_repaired = df.copy()\n",
    "        \n",
    "        print(\".\" * 40)\n",
    "        print(f\"Repairing: '{tag_to_repair}' → '{replacement}'\")\n",
    "        print(\">\" * 40)\n",
    "        \n",
    "        if scope == 'global':\n",
    "            replacements_made = 0\n",
    "            for col in df_repaired.columns:\n",
    "                # Count before\n",
    "                before_count = df_repaired[col].astype(str).str.contains(\n",
    "                    re.escape(tag_to_repair), regex=True\n",
    "                ).sum()\n",
    "                \n",
    "                # Make replacement - DON'T escape the replacement\n",
    "                df_repaired[col] = df_repaired[col].astype(str).str.replace(\n",
    "                    tag_to_repair, replacement, regex=False  # Use literal replacement\n",
    "                )\n",
    "                \n",
    "                # Count after\n",
    "                after_count = df_repaired[col].astype(str).str.contains(\n",
    "                    re.escape(tag_to_repair), regex=True\n",
    "                ).sum()\n",
    "                \n",
    "                column_replacements = before_count - after_count\n",
    "                if column_replacements > 0:\n",
    "                    print(f\"\\tColumn '{col}': {column_replacements} replacements\")\n",
    "                    # Show sample context with actual replacement\n",
    "                    sample_rows = df_repaired[col].astype(str).str.contains(\n",
    "                        re.escape(replacement), regex=True\n",
    "                    )\n",
    "                    if sample_rows.any():\n",
    "                        sample_idx = sample_rows.idxmax()\n",
    "                        context = self.html_analyzer.get_tag_context(\n",
    "                            df_repaired.loc[sample_idx, col], replacement\n",
    "                        )\n",
    "                        print(f\"\\t\\tSample context: {context[:100]}...\")\n",
    "                \n",
    "                replacements_made += column_replacements\n",
    "                \n",
    "            print(f\"Total replacements made: {replacements_made}\")\n",
    "            \n",
    "        elif scope == 'column' and specific_column:\n",
    "            if specific_column in df_repaired.columns:\n",
    "                df_repaired[specific_column] = df_repaired[specific_column].astype(str).str.replace(\n",
    "                    tag_to_repair, replacement, regex=False\n",
    "                )\n",
    "        elif scope == 'row' and specific_row is not None:\n",
    "            for col in df_repaired.columns:\n",
    "                if pd.notna(df_repaired.loc[specific_row, col]):\n",
    "                    cell_value = str(df_repaired.loc[specific_row, col])\n",
    "                    df_repaired.loc[specific_row, col] = cell_value.replace(tag_to_repair, replacement)\n",
    "        elif scope == 'cell' and specific_column and specific_row is not None:\n",
    "            if specific_column in df_repaired.columns and pd.notna(df_repaired.loc[specific_row, specific_column]):\n",
    "                cell_value = str(df_repaired.loc[specific_row, specific_column])\n",
    "                df_repaired.loc[specific_row, specific_column] = cell_value.replace(tag_to_repair, replacement)\n",
    "        \n",
    "        return df_repaired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be8a3c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4: Analyzing malformed tags...\n",
      "Scanning for actual HTML malformations...\n",
      "Found 16 actual HTML malformations\n",
      "Malformed Tags Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Malformed_Tag</th>\n",
       "      <th>Count</th>\n",
       "      <th>Suggested_Repair</th>\n",
       "      <th>Locations</th>\n",
       "      <th>Sample_Context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;bibbl&gt;</td>\n",
       "      <td>7</td>\n",
       "      <td>&lt;bibl&gt;</td>\n",
       "      <td>Row 18189, Col Attestations from sources in En...</td>\n",
       "      <td>e soil. (central Mexico, sixteenth century)&lt;br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;bibl&lt;</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;bibl&gt;</td>\n",
       "      <td>Row 2927, Col Attestations from sources in Spa...</td>\n",
       "      <td>fibras vegetales para transportar granos.\"&lt;br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>em</td>\n",
       "      <td>1</td>\n",
       "      <td>em</td>\n",
       "      <td>Row 2927, Col Attestations from sources in Spa...</td>\n",
       "      <td>s vegetales para transportar granos.\"&lt;br /&gt; &lt;b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;/wup&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;/wup&gt;</td>\n",
       "      <td>Row 3616, Col Attestations from sources in Eng...</td>\n",
       "      <td>l&gt;&lt;/p&gt; &lt;p&gt;ynic omochiuh missas 10 &lt;strong&gt;p&lt;wu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;bibi&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;bibl&gt;</td>\n",
       "      <td>Row 16873, Col Attestations from sources in En...</td>\n",
       "      <td>te: a \"tonsured\" priest had a shaved head.]&lt;br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bibl</td>\n",
       "      <td>1</td>\n",
       "      <td>bibl</td>\n",
       "      <td>Row 19677, Col Attestations from sources in En...</td>\n",
       "      <td>ished. (central Mexico, sixteenth century)&lt;br ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt;b9bl&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;bibl&gt;</td>\n",
       "      <td>Row 30486, Col Attestations from sources in En...</td>\n",
       "      <td>son of a Xonacatl who had died around 1530.&lt;br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>&lt;bobl&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;bibl&gt;</td>\n",
       "      <td>Row 30849, Col Alonso de Molina</td>\n",
       "      <td>uixti.) enxaguar la ropa despues de lauada.&lt;br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>&lt;/bobl&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;/bibl&gt;</td>\n",
       "      <td>Row 31700, Col Attestations from sources in Sp...</td>\n",
       "      <td>blicaciones/publicadigital/libros/cuentos_i......</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Malformed_Tag  Count Suggested_Repair  \\\n",
       "4       <bibbl>      7           <bibl>   \n",
       "0        <bibl<      2           <bibl>   \n",
       "1            em      1               em   \n",
       "2        </wup>      1           </wup>   \n",
       "3        <bibi>      1           <bibl>   \n",
       "5          bibl      1             bibl   \n",
       "6        <b9bl>      1           <bibl>   \n",
       "7        <bobl>      1           <bibl>   \n",
       "8       </bobl>      1          </bibl>   \n",
       "\n",
       "                                           Locations  \\\n",
       "4  Row 18189, Col Attestations from sources in En...   \n",
       "0  Row 2927, Col Attestations from sources in Spa...   \n",
       "1  Row 2927, Col Attestations from sources in Spa...   \n",
       "2  Row 3616, Col Attestations from sources in Eng...   \n",
       "3  Row 16873, Col Attestations from sources in En...   \n",
       "5  Row 19677, Col Attestations from sources in En...   \n",
       "6  Row 30486, Col Attestations from sources in En...   \n",
       "7                    Row 30849, Col Alonso de Molina   \n",
       "8  Row 31700, Col Attestations from sources in Sp...   \n",
       "\n",
       "                                      Sample_Context  \n",
       "4  e soil. (central Mexico, sixteenth century)<br...  \n",
       "0   fibras vegetales para transportar granos.\"<br...  \n",
       "1  s vegetales para transportar granos.\"<br /> <b...  \n",
       "2  l></p> <p>ynic omochiuh missas 10 <strong>p<wu...  \n",
       "3  te: a \"tonsured\" priest had a shaved head.]<br...  \n",
       "5  ished. (central Mexico, sixteenth century)<br ...  \n",
       "6  son of a Xonacatl who had died around 1530.<br...  \n",
       "7  uixti.) enxaguar la ropa despues de lauada.<br...  \n",
       "8  blicaciones/publicadigital/libros/cuentos_i......  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying repairs...\n",
      "Repairing '<bibbl>' -> '<bibl>'\n",
      "........................................\n",
      "Repairing: '<bibbl>' → '<bibl>'\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "\tColumn 'Attestations from sources in English': 7 replacements\n",
      "\t\tSample context: ne or not (Coyoacan, mid-sixteenth century)<br /> [[[<bibl>]]]Beyond the Codices, eds. Arthur J.O. A...\n",
      "Total replacements made: 7\n",
      "Repairing '<bibl<' -> '<bibl>'\n",
      "........................................\n",
      "Repairing: '<bibl<' → '<bibl>'\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "\tColumn 'Principal English Translation': 1 replacements\n",
      "\t\tSample context: <p>to do or make all; completely</p> <p>[[[<bibl>]]]Robert Haskett and Stephanie Wood's notes from N...\n",
      "\tColumn 'Attestations from sources in Spanish': 1 replacements\n",
      "\t\tSample context: liz = no se la quite nadie (Tlaxcala, 1609)<br /> [[[<bibl>]]]Vidas y bienes olvidados: Testamentos ...\n",
      "Total replacements made: 2\n",
      "Tag 'em' needs no repair\n",
      "Tag '</wup>' needs no repair\n",
      "Repairing '<bibi>' -> '<bibl>'\n",
      "........................................\n",
      "Repairing: '<bibi>' → '<bibl>'\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "\tColumn 'Attestations from sources in English': 1 replacements\n",
      "\t\tSample context: ne or not (Coyoacan, mid-sixteenth century)<br /> [[[<bibl>]]]Beyond the Codices, eds. Arthur J.O. A...\n",
      "Total replacements made: 1\n",
      "Tag 'bibl' needs no repair\n",
      "Repairing '<b9bl>' -> '<bibl>'\n",
      "........................................\n",
      "Repairing: '<b9bl>' → '<bibl>'\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "\tColumn 'Attestations from sources in English': 1 replacements\n",
      "\t\tSample context: ne or not (Coyoacan, mid-sixteenth century)<br /> [[[<bibl>]]]Beyond the Codices, eds. Arthur J.O. A...\n",
      "Total replacements made: 1\n",
      "Repairing '<bobl>' -> '<bibl>'\n",
      "........................................\n",
      "Repairing: '<bobl>' → '<bibl>'\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "\tColumn 'Alonso de Molina': 1 replacements\n",
      "\t\tSample context: <p>Acaçomo. quiça no. Aduerbio.<br /> [[[<bibl>]]] Alonso de Molina, Vocabulario en lengua mexicana ...\n",
      "Total replacements made: 1\n",
      "Repairing '</bobl>' -> '</bibl>'\n",
      "........................................\n",
      "Repairing: '</bobl>' → '</bibl>'\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "\tColumn 'Attestations from sources in Spanish': 1 replacements\n",
      "\t\tSample context: abiela, et al, eds. (México: CIESAS, 2002), 62–63.[[[</bibl>]]]</p> <p>ayac yconetzin = no tiene hij...\n",
      "Total replacements made: 1\n",
      "✓ Applied 9 HTML repairs\n",
      "Saved to: working_files\\04_malformed_tag_analysis.xlsx\n",
      "Saved to SQLite table: 04_malformed_repair_stage\n",
      "Step 4 complete: HTML malformation detection and repair\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Malformed Tag Detection and Repair\n",
    "print(\"Step 4: Analyzing malformed tags...\")\n",
    "\n",
    "# Use the enhanced MalformedTagRepairer class\n",
    "malformed_repairer = MalformedTagRepairer()\n",
    "malformed_results = malformed_repairer.analyze_malformed_tags(df)\n",
    "\n",
    "print(\"Malformed Tags Summary:\")\n",
    "if not malformed_results['Malformed_Tags_Summary'].empty:\n",
    "    display(malformed_results['Malformed_Tags_Summary'])\n",
    "    \n",
    "    # Save to SQLite\n",
    "    malformed_results['Malformed_Tags_Summary'].to_sql(\n",
    "        'malformed_tags_summary', conn, if_exists='replace', index=False\n",
    "    )\n",
    "    malformed_results['Malformed_Tags_by_Row'].to_sql(\n",
    "        'malformed_tags_by_row', conn, if_exists='replace', index=False\n",
    "    )\n",
    "    \n",
    "    # Apply repairs automatically\n",
    "    print(\"\\nApplying repairs...\")\n",
    "    for _, row in malformed_results['Malformed_Tags_Summary'].iterrows():  # Fixed syntax\n",
    "        malformed_tag = row['Malformed_Tag']\n",
    "        suggested_repair = row['Suggested_Repair']\n",
    "        if malformed_tag != suggested_repair:\n",
    "            print(f\"Repairing '{malformed_tag}' -> '{suggested_repair}'\")\n",
    "            df = malformed_repairer.repair_tags(\n",
    "                df, malformed_tag, suggested_repair, scope='global'\n",
    "            )\n",
    "        else:\n",
    "            print(f\"Tag '{malformed_tag}' needs no repair\")\n",
    "    \n",
    "    print(f\"✓ Applied {len(malformed_results['Malformed_Tags_Summary'])} HTML repairs\")\n",
    "    \n",
    "else:\n",
    "    print(\"No malformed HTML tags found!\")\n",
    "\n",
    "# Save to Excel and SQLite\n",
    "save_to_excel(malformed_results, \"04_malformed_tag_analysis.xlsx\")\n",
    "save_intermediate_stage_sqlite(df, \"04_malformed_repair\", conn)\n",
    "\n",
    "print(\"Step 4 complete: HTML malformation detection and repair\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6966f3",
   "metadata": {},
   "source": [
    "## Step 5: Non-HTML Tag Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a69fe1",
   "metadata": {},
   "source": [
    "## Step 6: Citation Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be34751",
   "metadata": {},
   "source": [
    "## Step 7: Cross-Reference Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f863c58",
   "metadata": {},
   "source": [
    "## Step 8: Complete Workflow Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cfc15b",
   "metadata": {},
   "source": [
    "## Individual Processing Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22e8867",
   "metadata": {},
   "source": [
    "## Usage Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e43c88",
   "metadata": {},
   "source": [
    "## DIY Data Clean-Up"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nahuaLEX_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
