{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df95143d",
   "metadata": {},
   "source": [
    "# Nahuatl Notebook for the WHP_EarlyNahuatl_Dataset\n",
    "\n",
    "This notebook processes Nahuatl dictionary data, analyzing HTML tags, repairing malformed tags, and extracting citations and cross-references. This is a merged version of Todd's version and I where there is a SQLite-based data management approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8105d6",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f542ca7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import hashlib\n",
    "import glob\n",
    "import csv\n",
    "import sqlite3\n",
    "from collections import defaultdict, Counter\n",
    "from typing import List, Dict, Tuple, Optional, Union\n",
    "from inscriptis import get_text\n",
    "from bs4 import BeautifulSoup\n",
    "from pathlib import Path\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "60814645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WHP_EarlyNahuatl_Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01_initial_stage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>html_tag_analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>malformed_tags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02_htmltag_analysis_stage</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        name\n",
       "0      WHP_EarlyNahuatl_Data\n",
       "1           01_initial_stage\n",
       "2          html_tag_analysis\n",
       "3             malformed_tags\n",
       "4  02_htmltag_analysis_stage"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create working directory\n",
    "os.makedirs('working_files', exist_ok=True)\n",
    "\n",
    "# load in the SQLite database holding the WHP Dataset\n",
    "conn = sqlite3.connect('../../data/sqLiteDb/Whp_Raw_Dataset.db')\n",
    "table_name = \"WHP_EarlyNahuatl_Data\"\n",
    "\n",
    "tables_query = \"SELECT name FROM sqlite_master WHERE type='table';\"\n",
    "tables = pd.read_sql(tables_query, conn)\n",
    "tables\n",
    "\n",
    "\n",
    "# If there's issues check the following\n",
    "# Possible solutions:\n",
    "# 1. Ensure the db file is in the correct directory\n",
    "# 2. Check the exact filename\n",
    "# 3. Verify the file extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cff32578",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_excel(data_dict: Dict[str, pd.DataFrame], filename: str, directory: str = 'working_files'):\n",
    "    \"\"\"Save multiple DataFrames as sheets in an Excel file\"\"\"\n",
    "    filepath = os.path.join(directory, filename)\n",
    "    with pd.ExcelWriter(filepath, engine='openpyxl') as writer:\n",
    "        for sheet_name, df in data_dict.items():\n",
    "            # Truncate sheet name if too long (Excel limit is 31 characters)\n",
    "            clean_sheet_name = sheet_name[:31] if len(sheet_name) > 31 else sheet_name\n",
    "            df.to_excel(writer, sheet_name=clean_sheet_name, index=False)\n",
    "    print(f\"Saved to: {filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2a92de2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataframe(df: pd.DataFrame, filename: str, directory: str = 'working_files'):\n",
    "    \"\"\"Save a single DataFrame to CSV\"\"\"\n",
    "    filepath = os.path.join(directory, filename)\n",
    "    df.to_csv(filepath, index=False)\n",
    "    print(f\"Saved to: {filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c2643a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_sqlite(df: pd.DataFrame, table_name: str, conn: sqlite3.Connection, if_exists: str = 'replace'):\n",
    "    \"\"\"Save DataFrame to SQLite table\"\"\"\n",
    "    df.to_sql(table_name, conn, if_exists=if_exists, index=False)\n",
    "    print(f\"Saved to SQLite table: {table_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86643dc",
   "metadata": {},
   "source": [
    "## Step 1: Import Data and Create Working Copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f5cdecdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_csv(filename: str) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"Load data and create a working copy\"\"\"\n",
    "    print(f\"Loading data from: {filename}\")\n",
    "\n",
    "    # Read the original data\n",
    "    original_df = pd.read_csv(filename)\n",
    "\n",
    "    # Create working copy\n",
    "    working_df = original_df.copy()\n",
    "\n",
    "    print(f\"Data loaded successfully:\")\n",
    "    print(f\"- Shape: {original_df.shape}\")\n",
    "    print(f\"- Columns: {list(original_df.columns)}\")\n",
    "\n",
    "    return original_df, working_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a6b20cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_sqlite(db_path: str, table_name: str = \"WHP_EarlyNahuatl_Data\") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"Load data from SQLite and create a working copy\"\"\"\n",
    "    print(f\"Loading data from: {db_path}\")\n",
    "    \n",
    "    conn = sqlite3.connect(db_path)\n",
    "    original_df = pd.read_sql(f\"SELECT * FROM {table_name}\", conn)\n",
    "    working_df = original_df.copy()\n",
    "    \n",
    "    print(f\"Data loaded successfully:\")\n",
    "    print(f\"- Shape: {original_df.shape}\")\n",
    "    print(f\"- Columns: {list(original_df.columns)}\")\n",
    "    \n",
    "    # Don't close connection yet - return it for later use\n",
    "    return original_df, working_df, conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a8466f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ref</th>\n",
       "      <th>Headword</th>\n",
       "      <th>Orthographic Variants</th>\n",
       "      <th>Principal English Translation</th>\n",
       "      <th>Attestations from sources in English</th>\n",
       "      <th>Attestations from sources in Spanish</th>\n",
       "      <th>Alonso de Molina</th>\n",
       "      <th>Frances Karttunen</th>\n",
       "      <th>Horacio Carochi / English</th>\n",
       "      <th>Andrés de Olmos</th>\n",
       "      <th>Lockhart’s Nahuatl as Written</th>\n",
       "      <th>themes</th>\n",
       "      <th>Spanish Loanword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WHP-171879</td>\n",
       "      <td>acazomo.</td>\n",
       "      <td>accaçomo, acaçomo</td>\n",
       "      <td>&lt;p&gt;perhaps not (adverb) (see Molina)&lt;/p&gt;</td>\n",
       "      <td>&lt;p&gt;acaçomo iuhqui yez yn anoço yuhquiez = whet...</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;p&gt;Acaçomo. quiça no. Aduerbio.&lt;br /&gt; &lt;bibl&gt; A...</td>\n",
       "      <td>&lt;p&gt;AHCAZOMŌ perhaps not / quizá no (M).  In on...</td>\n",
       "      <td>&lt;p&gt;àcaçomō = perhaps not&lt;br /&gt; &lt;bibl&gt;Horacio C...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WHP-171881</td>\n",
       "      <td>ayac.</td>\n",
       "      <td>aiaac</td>\n",
       "      <td>&lt;p&gt;no one; nobody; or, for someone to be absen...</td>\n",
       "      <td>&lt;p&gt;aiaac mic in mexica = None of the Mexica di...</td>\n",
       "      <td>&lt;p&gt;ayac guincuiliz = no se la quite nadie (Tla...</td>\n",
       "      <td>&lt;p&gt;Ayac. ninguno, o nadie o estar alguno ausen...</td>\n",
       "      <td>&lt;p&gt;AYĀC no one / ninguno, o nadie (M) See AH-,...</td>\n",
       "      <td>&lt;p&gt;ayāc = no one&lt;br /&gt; &lt;bibl&gt;Horacio Carochi, ...</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;p&gt;no one; nobody; or, for someone to be absen...</td>\n",
       "      <td>None</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WHP-171882</td>\n",
       "      <td>acan.</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;p&gt;nowhere, no place (see Molina, Karttunen, L...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;p&gt;acan. en ninguna parte o lugar. aduerbio.&lt;b...</td>\n",
       "      <td>&lt;p&gt;AHCĀN nowhere / en ninguna parte o lugar (M...</td>\n",
       "      <td>&lt;p&gt;àcān = nowhere&lt;br /&gt; &lt;bibl&gt;Horacio Carochi,...</td>\n",
       "      <td>&lt;p&gt;en ningun lugar, por, de, etc.&lt;br /&gt; &lt;bibl&gt;...</td>\n",
       "      <td>&lt;p&gt;ahcān = (particle) nowhere&lt;br /&gt; &lt;bibl&gt;Jame...</td>\n",
       "      <td>Cardinal Directions, Cosmos</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Ref  Headword Orthographic Variants  \\\n",
       "0  WHP-171879  acazomo.     accaçomo, acaçomo   \n",
       "1  WHP-171881     ayac.                 aiaac   \n",
       "2  WHP-171882     acan.                  None   \n",
       "\n",
       "                       Principal English Translation  \\\n",
       "0          <p>perhaps not (adverb) (see Molina)</p>    \n",
       "1  <p>no one; nobody; or, for someone to be absen...   \n",
       "2  <p>nowhere, no place (see Molina, Karttunen, L...   \n",
       "\n",
       "                Attestations from sources in English  \\\n",
       "0  <p>acaçomo iuhqui yez yn anoço yuhquiez = whet...   \n",
       "1  <p>aiaac mic in mexica = None of the Mexica di...   \n",
       "2                                               None   \n",
       "\n",
       "                Attestations from sources in Spanish  \\\n",
       "0                                               None   \n",
       "1  <p>ayac guincuiliz = no se la quite nadie (Tla...   \n",
       "2                                               None   \n",
       "\n",
       "                                    Alonso de Molina  \\\n",
       "0  <p>Acaçomo. quiça no. Aduerbio.<br /> <bibl> A...   \n",
       "1  <p>Ayac. ninguno, o nadie o estar alguno ausen...   \n",
       "2  <p>acan. en ninguna parte o lugar. aduerbio.<b...   \n",
       "\n",
       "                                   Frances Karttunen  \\\n",
       "0  <p>AHCAZOMŌ perhaps not / quizá no (M).  In on...   \n",
       "1  <p>AYĀC no one / ninguno, o nadie (M) See AH-,...   \n",
       "2  <p>AHCĀN nowhere / en ninguna parte o lugar (M...   \n",
       "\n",
       "                           Horacio Carochi / English  \\\n",
       "0  <p>àcaçomō = perhaps not<br /> <bibl>Horacio C...   \n",
       "1  <p>ayāc = no one<br /> <bibl>Horacio Carochi, ...   \n",
       "2  <p>àcān = nowhere<br /> <bibl>Horacio Carochi,...   \n",
       "\n",
       "                                     Andrés de Olmos  \\\n",
       "0                                               None   \n",
       "1                                               None   \n",
       "2  <p>en ningun lugar, por, de, etc.<br /> <bibl>...   \n",
       "\n",
       "                       Lockhart’s Nahuatl as Written  \\\n",
       "0                                               None   \n",
       "1  <p>no one; nobody; or, for someone to be absen...   \n",
       "2  <p>ahcān = (particle) nowhere<br /> <bibl>Jame...   \n",
       "\n",
       "                        themes Spanish Loanword  \n",
       "0                         None               No  \n",
       "1                         None               No  \n",
       "2  Cardinal Directions, Cosmos               No  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ref', 'Headword', 'Orthographic Variants', 'Principal English Translation', 'Attestations from sources in English', 'Attestations from sources in Spanish', 'Alonso de Molina', 'Frances Karttunen', 'Horacio Carochi / English', 'Andrés de Olmos', 'Lockhart’s Nahuatl as Written', 'themes', 'Spanish Loanword']\n"
     ]
    }
   ],
   "source": [
    "# Load your data\n",
    "\n",
    "original_df = pd.read_sql(\"SELECT * FROM WHP_EarlyNahuatl_Data\", conn)\n",
    "df = original_df.copy(deep=True)\n",
    "\n",
    "query = \"SELECT * FROM WHP_EarlyNahuatl_Data LIMIT 3;\"\n",
    "whp_dataset = pd.read_sql(query, conn)\n",
    "display(whp_dataset)\n",
    "\n",
    "cursor = conn.execute(f\"PRAGMA table_info({table_name})\")\n",
    "columns_info = cursor.fetchall()\n",
    "column_names = [col[1] for col in columns_info]\n",
    "\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f1d64e",
   "metadata": {},
   "source": [
    "## Step 2: Save Intermediate Stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f613b686",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_intermediate_stage(df: pd.DataFrame, stage_name: str):\n",
    "    \"\"\"Save intermediate processing stage\"\"\"\n",
    "    filename = f\"{stage_name}_stage.csv\"\n",
    "    save_dataframe(df, filename)\n",
    "    return df\n",
    "\n",
    "def save_intermediate_stage_sqlite(df: pd.DataFrame, stage_name: str, conn: sqlite3.Connection):\n",
    "    \"\"\"Save intermediate processing stage to SQLite\"\"\"\n",
    "    table_name = f\"{stage_name}_stage\"\n",
    "    save_to_sqlite(df, table_name, conn)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "45105fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save initial stage\n",
    "# save_intermediate_stage_sqlite(df, \"01_initial\", conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ca7114",
   "metadata": {},
   "source": [
    "## Step 3: HTML Tag Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8c717f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HTMLTagAnalyzer:\n",
    "    def __init__(self):\n",
    "        # HTML tags\n",
    "        self.html_tags = {\n",
    "            'p', 'br', 'div', 'span', 'a', 'b', 'i', 'u', 'strong', 'em',\n",
    "            'h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'ul', 'ol', 'li', 'table',\n",
    "            'tr', 'td', 'th', 'img', 'link', 'meta', 'head', 'body', 'html',\n",
    "            'bibl', 'title', 'sup', 'sub', 'del'\n",
    "        }\n",
    "        \n",
    "        # Define columns that should contain HTML content\n",
    "        self.content_columns = [\n",
    "            'Principal English Translation',\n",
    "            'Attestations from sources in English',\n",
    "            'Attestations from sources in Spanish',\n",
    "            'Alonso de Molina',\n",
    "            'Frances Karttunen', \n",
    "            'Horacio Carochi / English',\n",
    "            'Andrés de Olmos',\n",
    "            \"Lockhart's Nahuatl as Written\",\n",
    "            'Full Original Entry'\n",
    "        ]\n",
    "        \n",
    "        # Known malformed patterns to fix\n",
    "        self.malformed_patterns = {\n",
    "            r'</p</bibl>': '</p></bibl>',\n",
    "            r'<bibl<': '<bibl>',\n",
    "            r'</bibbl>': '</bibl>',\n",
    "            r'<bibbl>': '<bibl>',\n",
    "            r'<bobl>': '<bibl>',\n",
    "            r'</bobl>': '</bibl>',\n",
    "            r'<b9bl>': '<bibl>',\n",
    "            r'<bibi>': '<bibl>'\n",
    "        }\n",
    "    \n",
    "    def detect_malformed_tags(self, text: str) -> List[tuple]:\n",
    "        \"\"\"Detect specific malformed tag patterns\"\"\"\n",
    "        if pd.isna(text) or text == '':\n",
    "            return []\n",
    "        \n",
    "        malformed_found = []\n",
    "        text_str = str(text)\n",
    "        \n",
    "        # Check for known malformed patterns\n",
    "        for pattern, replacement in self.malformed_patterns.items():\n",
    "            if re.search(pattern, text_str):\n",
    "                malformed_found.append((pattern, replacement))\n",
    "        \n",
    "        # Define self-closing tags that shouldn't be counted in pair matching\n",
    "        self_closing_tags = {'br', 'hr', 'img', 'input', 'meta', 'link'}\n",
    "        \n",
    "        # Better tag counting using regex\n",
    "        for tag_name in self.html_tags:\n",
    "            if tag_name in self_closing_tags:\n",
    "                continue  # Skip self-closing tags\n",
    "            \n",
    "            # Use regex to properly count opening tags (with or without attributes)\n",
    "            # Matches <tag> or <tag attr=\"...\">~\n",
    "            open_pattern = f\"<{tag_name}(?:\\\\s+[^>]*)?>\"\n",
    "            close_pattern = f'</{tag_name}>'\n",
    "            \n",
    "            open_count = len(re.findall(open_pattern, text_str, re.IGNORECASE))\n",
    "            close_count = len(re.findall(close_pattern, text_str, re.IGNORECASE))\n",
    "            \n",
    "            if open_count != close_count:\n",
    "                malformed_found.append((f'<{tag_name}>', f'Mismatch: {open_count} open, {close_count} closed'))\n",
    "        return malformed_found\n",
    "    \n",
    "    def find_html_tags(self, text: str) -> List[str]:\n",
    "        \"\"\"Find all HTML-like tags in text with better handling of malformed tags\"\"\"\n",
    "        if pd.isna(text) or text == '':\n",
    "            return []\n",
    "        \n",
    "        # First fix known malformed patterns\n",
    "        text_str = str(text)\n",
    "        for pattern, replacement in self.malformed_patterns.items():\n",
    "            text_str = re.sub(pattern, replacement, text_str)\n",
    "        \n",
    "        # Then find tags\n",
    "        pattern = r'</?[^<>]+/?>'\n",
    "        matches = re.findall(pattern, text_str)\n",
    "        return matches\n",
    "    \n",
    "    def analyze_html_tags_in_dataframe(self, df: pd.DataFrame, \n",
    "                                      columns_to_check: List[str] = None) -> Dict[str, pd.DataFrame]:\n",
    "        \"\"\"Analyze HTML tags only in relevant columns\"\"\"\n",
    "        results = {\n",
    "            'tag_by_row': [],\n",
    "            'tag_summary': [],\n",
    "            'malformed_tags': []\n",
    "        }\n",
    "        \n",
    "        # Use specified columns or default to content columns\n",
    "        if columns_to_check is None:\n",
    "            columns_to_check = [col for col in self.content_columns if col in df.columns]\n",
    "        \n",
    "        # Track tags by row - only in relevant columns\n",
    "        for idx, row in df.iterrows():\n",
    "            for col in columns_to_check:\n",
    "                if col not in df.columns:\n",
    "                    continue\n",
    "                    \n",
    "                cell_value = row[col]\n",
    "                if pd.notna(cell_value) and cell_value != '':\n",
    "                    # Check for malformed tags first\n",
    "                    malformed = self.detect_malformed_tags(cell_value)\n",
    "                    if malformed:\n",
    "                        for pattern, fix in malformed:\n",
    "                            results['malformed_tags'].append({\n",
    "                                'Row': idx,\n",
    "                                'Column': col,\n",
    "                                'Pattern': pattern,\n",
    "                                'Suggested_Fix': fix,\n",
    "                                'Context': str(cell_value)[:100] + '...' if len(str(cell_value)) > 100 else str(cell_value)\n",
    "                            })\n",
    "                    \n",
    "                    # Find tags\n",
    "                    tags = self.find_html_tags(cell_value)\n",
    "                    for tag in tags:\n",
    "                        is_valid = self.is_valid_html_tag(tag)\n",
    "                        context = self.get_tag_context(cell_value, tag)\n",
    "                        results['tag_by_row'].append({\n",
    "                            'Row': idx,\n",
    "                            'Column': col,\n",
    "                            'Tag': tag,\n",
    "                            'Is_Valid_HTML': is_valid,\n",
    "                            'Context': context\n",
    "                        })\n",
    "        \n",
    "        # Create summaries\n",
    "        if results['tag_by_row']:\n",
    "            tag_by_row_df = pd.DataFrame(results['tag_by_row'])\n",
    "            \n",
    "            # Tag summary\n",
    "            tag_counts = Counter([item['Tag'] for item in results['tag_by_row']])\n",
    "            tag_locations = defaultdict(list)\n",
    "            \n",
    "            for item in results['tag_by_row']:\n",
    "                tag_locations[item['Tag']].append(f\"Row {item['Row']}, Col {item['Column']}\")\n",
    "            \n",
    "            for tag, count in tag_counts.items():\n",
    "                first_occurrence = next(item for item in results['tag_by_row'] if item['Tag'] == tag)\n",
    "                results['tag_summary'].append({\n",
    "                    'Tag': tag,\n",
    "                    'Count': count,\n",
    "                    'Is_Valid_HTML': first_occurrence['Is_Valid_HTML'],\n",
    "                    'Locations': '; '.join(tag_locations[tag][:5]) + ('...' if len(tag_locations[tag]) > 5 else ''),\n",
    "                    'Sample_Context': first_occurrence['Context']\n",
    "                })\n",
    "            \n",
    "            tag_summary_df = pd.DataFrame(results['tag_summary']).sort_values('Count', ascending=False)\n",
    "        else:\n",
    "            tag_by_row_df = pd.DataFrame()\n",
    "            tag_summary_df = pd.DataFrame()\n",
    "        \n",
    "        malformed_df = pd.DataFrame(results['malformed_tags']) if results['malformed_tags'] else pd.DataFrame()\n",
    "        \n",
    "        return {\n",
    "            'HTML_Tags_by_Row': tag_by_row_df,\n",
    "            'HTML_Tags_Summary': tag_summary_df,\n",
    "            'Malformed_Tags': malformed_df\n",
    "        }\n",
    "    \n",
    "    def is_valid_html_tag(self, tag: str) -> bool:\n",
    "        \"\"\"Check if a tag is a valid HTML tag with better error handling\"\"\"\n",
    "        try:\n",
    "            # Handle malformed tags better\n",
    "            if '<//' in tag or '><' in tag:  # Clearly malformed\n",
    "                return False\n",
    "            \n",
    "            # Remove < > and any attributes, get just the tag name\n",
    "            clean_tag = re.sub(r'^</?([^>\\s/]+).*>$', r'\\1', tag).lower()\n",
    "            \n",
    "            # Additional check for malformed tags\n",
    "            if '/' in clean_tag or '<' in clean_tag or '>' in clean_tag:\n",
    "                return False\n",
    "                \n",
    "            return clean_tag in self.html_tags\n",
    "        except:\n",
    "            return False\n",
    "    \n",
    "    def get_tag_context(self, text: str, tag: str, context_chars: int = 50) -> str:\n",
    "        \"\"\"Get context around a tag occurrence\"\"\"\n",
    "        if pd.isna(text) or text == '':\n",
    "            return ''\n",
    "        \n",
    "        text_str = str(text)\n",
    "        tag_pos = text_str.find(tag)\n",
    "        if tag_pos == -1:\n",
    "            return ''\n",
    "        \n",
    "        start = max(0, tag_pos - context_chars)\n",
    "        end = min(len(text_str), tag_pos + len(tag) + context_chars)\n",
    "        context = text_str[start:end]\n",
    "        \n",
    "        # Mark the tag in the context\n",
    "        tag_in_context = context.replace(tag, f\"[[[{tag}]]]\")\n",
    "        return tag_in_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c3026a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: working_files\\02_html_tag_analysis.xlsx\n"
     ]
    }
   ],
   "source": [
    "html_analyzer = HTMLTagAnalyzer()\n",
    "html_results = html_analyzer.analyze_html_tags_in_dataframe(df)\n",
    "\n",
    "html_results['HTML_Tags_Summary'].to_sql('html_tag_analysis', conn, if_exists='replace', index=False)\n",
    "html_results['Malformed_Tags'].to_sql('malformed_tags', conn, if_exists='replace', index=False)\n",
    "\n",
    "# save_intermediate_stage_sqlite(df, \"02_htmltag_analysis\", conn)\n",
    "save_to_excel(html_results, \"02_html_tag_analysis.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd09fe05",
   "metadata": {},
   "source": [
    "## Step 4: Malformed Tag Detection and Repair"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6966f3",
   "metadata": {},
   "source": [
    "## Step 5: Non-HTML Tag Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a69fe1",
   "metadata": {},
   "source": [
    "## Step 6: Citation Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be34751",
   "metadata": {},
   "source": [
    "## Step 7: Cross-Reference Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f863c58",
   "metadata": {},
   "source": [
    "## Step 8: Complete Workflow Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cfc15b",
   "metadata": {},
   "source": [
    "## Individual Processing Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22e8867",
   "metadata": {},
   "source": [
    "## Usage Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e43c88",
   "metadata": {},
   "source": [
    "## DIY Data Clean-Up"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nahuaLEX_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
